<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Bayesian Statistics</title>
  <meta name="description" content="This book is a written companion for the Course Course ‘Bayesian Statistics’ from the Statistics with R specialization.">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="Bayesian Statistics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://www.coursera.org/learn/bayesian/home/info/" />
  <meta property="og:image" content="http://www.coursera.org/learn/bayesian/home/info/cover.png" />
  <meta property="og:description" content="This book is a written companion for the Course Course ‘Bayesian Statistics’ from the Statistics with R specialization." />
  <meta name="github-repo" content="StatsWithR/book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bayesian Statistics" />
  
  <meta name="twitter:description" content="This book is a written companion for the Course Course ‘Bayesian Statistics’ from the Statistics with R specialization." />
  <meta name="twitter:image" content="http://www.coursera.org/learn/bayesian/home/info/cover.png" />

<meta name="author" content="Christine Chai">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="inference-for-multiple-parameters.html">
<link rel="next" href="monte-carlo-simulation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="the-basics-of-bayesian-statistics.html"><a href="the-basics-of-bayesian-statistics.html"><i class="fa fa-check"></i><b>1</b> The Basics of Bayesian Statistics</a><ul>
<li class="chapter" data-level="1.1" data-path="bayes-rule.html"><a href="bayes-rule.html"><i class="fa fa-check"></i><b>1.1</b> Bayes’ Rule</a><ul>
<li class="chapter" data-level="1.1.1" data-path="bayes-rule.html"><a href="bayes-rule.html#sec:bayes-rule"><i class="fa fa-check"></i><b>1.1.1</b> Conditional Probabilities &amp; Bayes’ Rule</a></li>
<li class="chapter" data-level="1.1.2" data-path="bayes-rule.html"><a href="bayes-rule.html#diagnostic-testing"><i class="fa fa-check"></i><b>1.1.2</b> Bayes’ Rule and Diagnostic Testing</a></li>
<li class="chapter" data-level="1.1.3" data-path="bayes-rule.html"><a href="bayes-rule.html#bayes-updating"><i class="fa fa-check"></i><b>1.1.3</b> Bayes Updating</a></li>
<li class="chapter" data-level="1.1.4" data-path="bayes-rule.html"><a href="bayes-rule.html#bayesian-vs.frequentist-definitions-of-probability"><i class="fa fa-check"></i><b>1.1.4</b> Bayesian vs. Frequentist Definitions of Probability</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html"><i class="fa fa-check"></i><b>1.2</b> Inference for a Proportion</a><ul>
<li class="chapter" data-level="1.2.1" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#inference-for-a-proportion-frequentist-approach"><i class="fa fa-check"></i><b>1.2.1</b> Inference for a Proportion: Frequentist Approach</a></li>
<li class="chapter" data-level="1.2.2" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#inference-for-a-proportion-bayesian-approach"><i class="fa fa-check"></i><b>1.2.2</b> Inference for a Proportion: Bayesian Approach</a></li>
<li class="chapter" data-level="1.2.3" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#effect-of-sample-size-on-the-posterior"><i class="fa fa-check"></i><b>1.2.3</b> Effect of Sample Size on the Posterior</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="frequentist-vs-bayesian-inference.html"><a href="frequentist-vs-bayesian-inference.html"><i class="fa fa-check"></i><b>1.3</b> Frequentist vs. Bayesian Inference</a><ul>
<li class="chapter" data-level="1.3.1" data-path="frequentist-vs-bayesian-inference.html"><a href="frequentist-vs-bayesian-inference.html#frequentist-vs.bayesian-inference-1"><i class="fa fa-check"></i><b>1.3.1</b> Frequentist vs. Bayesian Inference</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>2</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="2.1" data-path="continuous-variables-and-eliciting-probability-distributions.html"><a href="continuous-variables-and-eliciting-probability-distributions.html"><i class="fa fa-check"></i><b>2.1</b> Continuous Variables and Eliciting Probability Distributions</a><ul>
<li class="chapter" data-level="2.1.1" data-path="continuous-variables-and-eliciting-probability-distributions.html"><a href="continuous-variables-and-eliciting-probability-distributions.html#from-the-discrete-to-the-continuous"><i class="fa fa-check"></i><b>2.1.1</b> From the Discrete to the Continuous</a></li>
<li class="chapter" data-level="2.1.2" data-path="continuous-variables-and-eliciting-probability-distributions.html"><a href="continuous-variables-and-eliciting-probability-distributions.html#elicitation"><i class="fa fa-check"></i><b>2.1.2</b> Elicitation</a></li>
<li class="chapter" data-level="2.1.3" data-path="continuous-variables-and-eliciting-probability-distributions.html"><a href="continuous-variables-and-eliciting-probability-distributions.html#conjugacy"><i class="fa fa-check"></i><b>2.1.3</b> Conjugacy</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="three-conjugate-families.html"><a href="three-conjugate-families.html"><i class="fa fa-check"></i><b>2.2</b> Three Conjugate Families</a><ul>
<li class="chapter" data-level="2.2.1" data-path="three-conjugate-families.html"><a href="three-conjugate-families.html#inference-on-a-binomial-proportion"><i class="fa fa-check"></i><b>2.2.1</b> Inference on a Binomial Proportion</a></li>
<li class="chapter" data-level="2.2.2" data-path="three-conjugate-families.html"><a href="three-conjugate-families.html#the-gamma-poisson-conjugate-families"><i class="fa fa-check"></i><b>2.2.2</b> The Gamma-Poisson Conjugate Families</a></li>
<li class="chapter" data-level="2.2.3" data-path="three-conjugate-families.html"><a href="three-conjugate-families.html#sec:normal-normal"><i class="fa fa-check"></i><b>2.2.3</b> The Normal-Normal Conjugate Families</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="credible-intervals-and-predictive-inference.html"><a href="credible-intervals-and-predictive-inference.html"><i class="fa fa-check"></i><b>2.3</b> Credible Intervals and Predictive Inference</a><ul>
<li class="chapter" data-level="2.3.1" data-path="credible-intervals-and-predictive-inference.html"><a href="credible-intervals-and-predictive-inference.html#non-conjugate-priors"><i class="fa fa-check"></i><b>2.3.1</b> Non-Conjugate Priors</a></li>
<li class="chapter" data-level="2.3.2" data-path="credible-intervals-and-predictive-inference.html"><a href="credible-intervals-and-predictive-inference.html#credible-intervals"><i class="fa fa-check"></i><b>2.3.2</b> Credible Intervals</a></li>
<li class="chapter" data-level="2.3.3" data-path="credible-intervals-and-predictive-inference.html"><a href="credible-intervals-and-predictive-inference.html#predictive-inference"><i class="fa fa-check"></i><b>2.3.3</b> Predictive Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="losses-and-decision-making.html"><a href="losses-and-decision-making.html"><i class="fa fa-check"></i><b>3</b> Losses and Decision-making</a><ul>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="losses-and-decision-making-1.html"><a href="losses-and-decision-making-1.html"><i class="fa fa-check"></i><b>3.2</b> Losses and Decision Making</a></li>
<li class="chapter" data-level="3.3" data-path="working-with-loss-functions.html"><a href="working-with-loss-functions.html"><i class="fa fa-check"></i><b>3.3</b> Working with Loss Functions</a></li>
<li class="chapter" data-level="3.4" data-path="minimizing-expectated-loss-for-hypothesis-testing.html"><a href="minimizing-expectated-loss-for-hypothesis-testing.html"><i class="fa fa-check"></i><b>3.4</b> Minimizing Expectated Loss for Hypothesis Testing</a></li>
<li class="chapter" data-level="3.5" data-path="posterior-probabilities-of-hypotheses-and-bayes-factors.html"><a href="posterior-probabilities-of-hypotheses-and-bayes-factors.html"><i class="fa fa-check"></i><b>3.5</b> Posterior Probabilities of Hypotheses and Bayes Factors</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inference-for-multiple-parameters.html"><a href="inference-for-multiple-parameters.html"><i class="fa fa-check"></i><b>4</b> Inference for Multiple Parameters</a><ul>
<li class="chapter" data-level="4.1" data-path="sec-normal-gamma.html"><a href="sec-normal-gamma.html"><i class="fa fa-check"></i><b>4.1</b> Inference for Normal Mean with Unknown Variance</a><ul>
<li class="chapter" data-level="4.1.1" data-path="sec-normal-gamma.html"><a href="sec-normal-gamma.html#sampling-model"><i class="fa fa-check"></i><b>4.1.1</b> Sampling Model</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec-normal-gamma.html"><a href="sec-normal-gamma.html#conjugate-prior"><i class="fa fa-check"></i><b>4.1.2</b> Conjugate prior</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec-normal-gamma.html"><a href="sec-normal-gamma.html#posterior-distribution"><i class="fa fa-check"></i><b>4.1.3</b> Posterior Distribution</a></li>
<li class="chapter" data-level="4.1.4" data-path="sec-normal-gamma.html"><a href="sec-normal-gamma.html#marginal-distribution-for-mu"><i class="fa fa-check"></i><b>4.1.4</b> Marginal Distribution for <span class="math inline">\(\mu\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="monte-carlo-simulation.html"><a href="monte-carlo-simulation.html"><i class="fa fa-check"></i><b>4.2</b> Monte Carlo Simulation</a></li>
<li class="chapter" data-level="4.3" data-path="predictive-distributions.html"><a href="predictive-distributions.html"><i class="fa fa-check"></i><b>4.3</b> Predictive Distributions</a></li>
<li class="chapter" data-level="4.4" data-path="reference-priors.html"><a href="reference-priors.html"><i class="fa fa-check"></i><b>4.4</b> Reference Priors</a></li>
<li class="chapter" data-level="4.5" data-path="beyond-conjugate-priors-using-mixtures.html"><a href="beyond-conjugate-priors-using-mixtures.html"><i class="fa fa-check"></i><b>4.5</b> Beyond Conjugate Priors using Mixtures</a></li>
<li class="chapter" data-level="4.6" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>4.6</b> Markov Chain Monte Carlo</a></li>
<li class="chapter" data-level="4.7" data-path="excercises.html"><a href="excercises.html"><i class="fa fa-check"></i><b>4.7</b> Excercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-testing-for-one-and-two-normal-samples.html"><a href="hypothesis-testing-for-one-and-two-normal-samples.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Testing for One and Two Normal Samples</a><ul>
<li class="chapter" data-level="5.1" data-path="bayes-factors-for-testing-a-normal-mean-variance-known.html"><a href="bayes-factors-for-testing-a-normal-mean-variance-known.html"><i class="fa fa-check"></i><b>5.1</b> Bayes Factors for Testing a Normal Mean: Variance Known</a></li>
<li class="chapter" data-level="5.2" data-path="bayes-factors-for-testing-a-normal-mean-variance-unknown.html"><a href="bayes-factors-for-testing-a-normal-mean-variance-unknown.html"><i class="fa fa-check"></i><b>5.2</b> Bayes Factors for Testing a Normal Mean: Variance Unknown</a></li>
<li class="chapter" data-level="5.3" data-path="bayes-factors-for-hypotheses-about-means-in-two-groups.html"><a href="bayes-factors-for-hypotheses-about-means-in-two-groups.html"><i class="fa fa-check"></i><b>5.3</b> Bayes Factors for Hypotheses about Means in Two Groups</a></li>
<li class="chapter" data-level="5.4" data-path="credible-intervals-after-hypothesis-testing.html"><a href="credible-intervals-after-hypothesis-testing.html"><i class="fa fa-check"></i><b>5.4</b> Credible Intervals after Hypothesis Testing</a></li>
<li class="chapter" data-level="5.5" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec:normal-gamma" class="section level2">
<h2><span class="header-section-number">4.1</span> Inference for Normal Mean with Unknown Variance</h2>
<p>In <a href="three-conjugate-families.html#sec:normal-normal">2.2.3</a> we described the normal-normal conjugate family for inference about an unknown mean <span class="math inline">\(\mu\)</span> with a known standard deviation <span class="math inline">\(\sigma\)</span> when the data were assumed to be a random sample from a normal population. In this section we will introduce the normal-gamma conjugate family for the common situation when <span class="math inline">\(\sigma\)</span> is unknown.</p>
<div id="sampling-model" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Sampling Model</h3>
<p>Recall that a conjugate pair is a sampling model for the data and prior distribution for the unknown parameters such that the posterior distribution is in the same family of distributions as the prior distribution. We will assume that the data are a random sample of size <span class="math inline">\(n\)</span> from a normal population with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>; the following is a mathematical shorthand to represent this distribution assumption</p>
<p><span class="math display">\[\begin{equation}
Y_1, \ldots Y_n  {\mathrel{\mathop{\sim}\limits^{\rm iid}}}\textsf{N}(\mu, \sigma^2) 
\end{equation}\]</span> where iid above the distributed as symbol ‘<span class="math inline">\(\sim\)</span>’ indicates that each of the observations are <strong>i</strong>ndependent of the others (given <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>) and are <strong>i</strong>dentically <strong>d</strong>istributed. As both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> unknown, we will need to specify a <strong>joint</strong> prior distribution to describe our prior uncertainty about them.</p>
</div>
<div id="conjugate-prior" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Conjugate prior</h3>
If you recall from <a href="three-conjugate-families.html#sec:normal-normal">2.2.3</a> the conjugate prior for <span class="math inline">\(\mu\)</span> with a known standard deviation <span class="math inline">\(\sigma\)</span> was a normal distribution. We will build on this to specify the conditional prior distribution for <span class="math inline">\(\mu\)</span> as
<span class="math display" id="eq:04-conjugate-normal">\[\begin{equation}
\mu \mid \sigma^2   \sim  \textsf{N}(m_0, \sigma^2/n_0)
\tag{4.1}
\end{equation}\]</span>
<p>with hyper-parameters <span class="math inline">\(m_0\)</span>, the prior mean for <span class="math inline">\(\mu\)</span>, and <span class="math inline">\(\sigma^2/n_0\)</span> the prior variance. While previously the variance was a known constant <span class="math inline">\(\tau^2\)</span>, replacing <span class="math inline">\(\tau^2\)</span> with a multiple of <span class="math inline">\(\sigma^2\)</span> is necessary for the joint conjugate prior. Because <span class="math inline">\(\sigma\)</span> has the same units as the data, the hyper-parameter <span class="math inline">\(n_0\)</span> is unitless, but is used to express our prior precision about <span class="math inline">\(\mu\)</span> with larger values of <span class="math inline">\(n_0\)</span> indicating more precision and smaller values less precision. We will see later how the hyper-parameter <span class="math inline">\(n_0\)</span> may be interpreted as a prior sample size.</p>
As <span class="math inline">\(\sigma^2\)</span> is unknown, a Bayesian would use a prior distribution to describe the uncertainty about the variance before seeing data. Since the variance is non-negative, continuous, and with no upper limit, you might think that a gamma distribution would be a candidate for a conjugate prior for the variance, based on the distributions that we have seen so far. That is close, but it turns out that it is actually the inverse of the variance, which is known as the precision, that has a conjugate gamma prior distribution. Letting <span class="math inline">\(\phi = 1/\sigma^2\)</span> denote the precision or inverse variance, the conjugate prior for <span class="math inline">\(\phi\)</span>,
<span class="math display" id="eq:04-conjugate-gamma">\[\begin{equation}
\phi \sim \textsf{Gamma}\left(\frac{v_0}{2}, \frac{v_0 s^2_0}{2} \right)
\tag{4.2}
\end{equation}\]</span>
is a gamma distribution with prior degrees of freedom <span class="math inline">\(v_0\)</span> and prior variance <span class="math inline">\(s^2_0\)</span>. Equivalently we may say that the inverse of the variance has a <span class="math display">\[1/\sigma^2 \sim \textsf{Gamma}(v_0/2, s^2_0 v_0/2)\]</span> gamma distribution. Together the Normal conditional distribution for <span class="math inline">\(\mu\)</span> given <span class="math inline">\(\sigma^2\)</span> in <a href="sec-normal-gamma.html#eq:04-conjugate-normal">(4.1)</a> and the marginal Gamma distribution for <span class="math inline">\(\phi\)</span> in <a href="sec-normal-gamma.html#eq:04-conjugate-gamma">(4.2)</a> leads to a joint distribution for the pair <span class="math inline">\((\mu, \phi)\)</span> that we will call the Normal-Gamma family of distributions
<span class="math display" id="eq:04-cojugate-normal-gamma">\[\begin{equation}(\mu, \phi) \sim \textsf{NormalGamma}(m_0, n_0, s^2_0, v_0)
\tag{4.3}
\end{equation}\]</span>
<p>with four hyperparameters <span class="math inline">\(m_0\)</span>, <span class="math inline">\(n_0\)</span>, <span class="math inline">\(s^2_0\)</span>, and <span class="math inline">\(v_0\)</span>.</p>
</div>
<div id="posterior-distribution" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Posterior Distribution</h3>
As a conjugate family the posterior distribution of the parameters is in the same family as the prior distribution. As a conjugate prior for a sample from a normal distribution, the posterior is also Normal-Gamma
<span class="math display">\[\begin{equation}
(\mu, \phi) \mid \text{data} \sim \textsf{NormalGamma}(m_n, n_n, s^2_n, v_n)
\end{equation}\]</span>
where the subscript <span class="math inline">\(n\)</span> on the hyper-parameters indicates the updated values after seeing the <span class="math inline">\(n\)</span> observations from the data:
<span class="math display">\[\begin{eqnarray*}
m_n &amp; = &amp; \frac{n \bar{Y} + n_0 m_0} {n + n_0}  \\
&amp; \\
n_n &amp; = &amp; n_0 + n  \\
v_n &amp; = &amp; v_0 + n  \\
s^2_n &amp; =  &amp; \frac{1}{v_n}\left[s^2_0 v_0 + s^2 (n-1) + \frac{n_0 n}{n_n} (\bar{Y} - m_0)^2 \right] 
\end{eqnarray*}\]</span>
<p>The updated hyperparameter <span class="math inline">\(m_n\)</span> in the posterior distribution of <span class="math inline">\(\mu\)</span> is the posterior mean, which is a weighted average of the sample mean <span class="math inline">\(\bar{Y}\)</span> and prior mean <span class="math inline">\(m_0\)</span> with weights <span class="math inline">\(n/(n + n_0\)</span> and <span class="math inline">\(n_0/(n + n_0)\)</span> respectively. The posterior sample size <span class="math inline">\(n_n\)</span> is the sum of the prior sample size <span class="math inline">\(n_n\)</span> and the sample size <span class="math inline">\(n\)</span>, representing the combined precision of the estimate for <span class="math inline">\(\mu\)</span>.</p>
<p>The posterior degrees of freedom <span class="math inline">\(v_n\)</span> are also increased by adding the sample size <span class="math inline">\(n\)</span> to the prior degrees of freedom <span class="math inline">\(v_0\)</span>.</p>
<p>The posterior variance hyper-parameter <span class="math inline">\(s^2_n\)</span> combines three sources of information about <span class="math inline">\(\sigma\)</span> in terms of sums of squared deviations. The first term in the square brackets is the sample variance times the sample degrees of freedom which is the sample sum of squares. The second term represents the prior sum of squares, while the third term is based on the squared difference of the sample mean and prior mean. We then divide by the posterior degrees of freedom to get the new variance.</p>
<p>The joint Normal-Gamma distribution for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span>, <span class="math inline">\((\mu, \phi) \mid {\text{data}}\sim {\textsf{NormalGamma}}(m_n, n_n, s^2_n, v_n)\)</span> is equivalent to a hierarchical model with <span class="math inline">\(\mu\)</span> given <span class="math inline">\(\sigma\)</span> having a conditional normal distribution <span class="math display">\[\begin{aligned}
\mu \mid {\text{data}}, \sigma^2  &amp;\sim  {\textsf{N}}(m_n, \sigma^2/n_n)  \\
1/\sigma^2 \mid {\text{data}}&amp; \sim   {\textsf{Gamma}}(v_n/2, s^2_n v_n/2) \pause
\end{aligned}
\]</span> and the inverse variance having a marginal gamma distribution.</p>
</div>
<div id="marginal-distribution-for-mu" class="section level3">
<h3><span class="header-section-number">4.1.4</span> Marginal Distribution for <span class="math inline">\(\mu\)</span></h3>
<p>Since we are interested in inference about mu unconditionally, we need the marginal distribution of mu that averages over the uncertainty in <span class="math inline">\(\sigma\)</span>. One can show by integration that the marginal distribution for <span class="math inline">\(\mu\)</span> is a Student t distribution <span class="math display">\[\begin{aligned} \mu \mid {\text{data}}\sim {\textsf{t}}(v_n, m_n, s^2_n/n_n) \pause
 \Leftrightarrow  t = \frac{\mu - m_n}{s_n/\sqrt{n_n}} \sim {\textsf{t}}(v_n, 0 , 1)
 \end{aligned}
\]</span> with density <span class="math display">\[
\begin{aligned}
p(t) =\frac{\Gamma\left(\frac{v_n + 1}{2} \right)}
{\sqrt{\pi v_n} \Gamma\left(\frac{v_n}{2} \right)}
\left(1 + \frac{1}{v_n}\frac{(\mu - m_n)^2} {s^2_n/n_n} \right)^{-\frac{v_n+1}{2}}
\end{aligned}\]</span> with the degrees of freedom <span class="math inline">\(v_n\)</span>, a location parameter <span class="math inline">\(m_n\)</span> and squared scale parameter that is the posterior variance parameter divided by the posterior sample size.</p>
<p>standardizing mu by subtracting the location and dividing by the scale yields a standard t distribution with degrees of freedom v_n, location 0 and scale 1. The latter representation allows us to use standard statistical functions for posterior inference.</p>
<p>Let’s look at an example based on a sample of total trihalomethanes or TTHM in tapwater from a city in NC, that can be loaded from the <code>statsr</code> package</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(statsr)
<span class="kw">data</span>(tapwater)</code></pre></div>
<p>Using prior information about TTHM from the city, I will use a Normal-Gamma prior distribution with prior mean of 35 parts per billion based on a prior sample size of twenty-five and an estimate of the variance of one hundred fifty-six point two five with degrees of freedom twenty-four. In section <strong>ADD REFERENCE</strong>, we will describe how we arrived at these values.</p>
<p>Using the sample mean of 55.5 and the sample variance five hundred forty point seven from the sample of size 28 we obtain the following update the hyper-parameters</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_0 =<span class="st"> </span><span class="dv">35</span>; n_0 =<span class="st"> </span><span class="dv">25</span>; s2_0 =<span class="st"> </span><span class="fl">156.25</span>; v_0 =<span class="st"> </span>n_0 -<span class="st"> </span><span class="dv">1</span>

Y =<span class="st"> </span>tapwater$tthm
ybar =<span class="st"> </span><span class="kw">mean</span>(Y)
s2 =<span class="st"> </span><span class="kw">var</span>(Y)
n =<span class="st"> </span><span class="kw">length</span>(Y)
n_n =<span class="st"> </span>n_0 +<span class="st"> </span>n
m_n =<span class="st"> </span>(n*ybar +<span class="st"> </span>n_0*m_0)/n_n
v_n =<span class="st"> </span>v_0 +<span class="st"> </span>n
s2_n =<span class="st"> </span>((n<span class="dv">-1</span>)*s2 +<span class="st"> </span>v_0*s2_0 +<span class="st"> </span>n_0*n*(m_0 -<span class="st"> </span>ybar)^<span class="dv">2</span>/n_n)/v_n</code></pre></div>
<p>Prior <span class="math inline">\(\textsf{NormalGamma}(35, 25, \Sexpr{s2_0}, \Sexpr{v_0})\)</span></p>
<p>Data <span class="math inline">\(\bar{Y} = \Sexpr{ybar}\)</span>, <span class="math inline">\(s^2 = \Sexpr{s2}\)</span>, <span class="math inline">\(n = \Sexpr{n}\)</span> providing the normal-gamma posterior that summarizes our posterior uncertainty after seeing the data.</p>
<p>To find a credible interval for the mean, we use the Student t distribution. Since the distribution of mu is unimodal and symmetric, the shortest 95 percent credible interval or the Highest Posterior Density interval, HPD for short, is the orange interval given by the Lower endpoint L and upper endpoint U where the probability that mu is in the interval (L, U) is the shaded area which is equal to zero point nine five.</p>
<p>using the standardized t distribution and some algebra, these values are based on the quantiles of the standard t distribution times the scale plus the posterior mean and should look familiar to expressions for confidence intervals from frequentist statistics.</p>
<p>The following code illustrates using R to calculate the 95 percent credible interval using quantiles from the standard t distribution. The tap water data are available from the statsr package.</p>
<p>Based on the updated posterior, we find that there is a 95 chance that the mean TTHM concentration is between 39.9 parts per billion and 51.8 parts per billion.</p>
<p>To recap, we introduced the normal -gamma conjugate prior for inference about an unknown mean and variance for samples from a normal distribution.</p>
<p>We described how the joint normal-gamma distribution leads to the student t distribution for inference about mu when sigma is unknown,</p>
<p>and showed how to obtain credible intervals for mu using R.</p>
<p>next, we will introduce Monte Carlo sampling to explore prior and posterior distributions in more detail.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inference-for-multiple-parameters.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="monte-carlo-simulation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-normal-01-conjugate.Rmd",
"text": "Edit"
},
"download": ["Bayes_Book.pdf", "Bayes_Book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
