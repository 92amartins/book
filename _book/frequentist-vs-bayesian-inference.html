<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Bayesian Statistics</title>
  <meta name="description" content="This book is a written companion for the Course Course ‘Bayesian Statistics’ from the Statistics with R specialization.">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="Bayesian Statistics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://www.coursera.org/learn/bayesian/home/info/" />
  <meta property="og:image" content="http://www.coursera.org/learn/bayesian/home/info/cover.png" />
  <meta property="og:description" content="This book is a written companion for the Course Course ‘Bayesian Statistics’ from the Statistics with R specialization." />
  <meta name="github-repo" content="StatsWithR/book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bayesian Statistics" />
  
  <meta name="twitter:description" content="This book is a written companion for the Course Course ‘Bayesian Statistics’ from the Statistics with R specialization." />
  <meta name="twitter:image" content="http://www.coursera.org/learn/bayesian/home/info/cover.png" />

<meta name="author" content="Christine Chai">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="inference-for-a-proportion.html">
<link rel="next" href="exercises.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="the-basics-of-bayesian-statistics.html"><a href="the-basics-of-bayesian-statistics.html"><i class="fa fa-check"></i><b>1</b> The Basics of Bayesian Statistics</a><ul>
<li class="chapter" data-level="1.1" data-path="bayes-rule.html"><a href="bayes-rule.html"><i class="fa fa-check"></i><b>1.1</b> Bayes’ Rule</a><ul>
<li class="chapter" data-level="1.1.1" data-path="bayes-rule.html"><a href="bayes-rule.html#bayes-rule"><i class="fa fa-check"></i><b>1.1.1</b> Conditional Probabilities &amp; Bayes’ Rule</a></li>
<li class="chapter" data-level="1.1.2" data-path="bayes-rule.html"><a href="bayes-rule.html#diagnostic-testing"><i class="fa fa-check"></i><b>1.1.2</b> Bayes’ Rule and Diagnostic Testing</a></li>
<li class="chapter" data-level="1.1.3" data-path="bayes-rule.html"><a href="bayes-rule.html#bayes-updating"><i class="fa fa-check"></i><b>1.1.3</b> Bayes Updating</a></li>
<li class="chapter" data-level="1.1.4" data-path="bayes-rule.html"><a href="bayes-rule.html#bayesian-vs.frequentist-definitions-of-probability"><i class="fa fa-check"></i><b>1.1.4</b> Bayesian vs. Frequentist Definitions of Probability</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html"><i class="fa fa-check"></i><b>1.2</b> Inference for a Proportion</a><ul>
<li class="chapter" data-level="1.2.1" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#inference-for-a-proportion-frequentist-approach"><i class="fa fa-check"></i><b>1.2.1</b> Inference for a Proportion: Frequentist Approach</a></li>
<li class="chapter" data-level="1.2.2" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#inference-for-a-proportion-bayesian-approach"><i class="fa fa-check"></i><b>1.2.2</b> Inference for a Proportion: Bayesian Approach</a></li>
<li class="chapter" data-level="1.2.3" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#effect-of-sample-size-on-the-posterior"><i class="fa fa-check"></i><b>1.2.3</b> Effect of Sample Size on the Posterior</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="frequentist-vs-bayesian-inference.html"><a href="frequentist-vs-bayesian-inference.html"><i class="fa fa-check"></i><b>1.3</b> Frequentist vs. Bayesian Inference</a><ul>
<li class="chapter" data-level="1.3.1" data-path="frequentist-vs-bayesian-inference.html"><a href="frequentist-vs-bayesian-inference.html#frequentist-vs.bayesian-inference-1"><i class="fa fa-check"></i><b>1.3.1</b> Frequentist vs. Bayesian Inference</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>2</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="2.1" data-path="continuous-variables-and-eliciting-probability-distributions.html"><a href="continuous-variables-and-eliciting-probability-distributions.html"><i class="fa fa-check"></i><b>2.1</b> Continuous Variables and Eliciting Probability Distributions</a><ul>
<li class="chapter" data-level="2.1.1" data-path="continuous-variables-and-eliciting-probability-distributions.html"><a href="continuous-variables-and-eliciting-probability-distributions.html#from-the-discrete-to-the-continuous"><i class="fa fa-check"></i><b>2.1.1</b> From the Discrete to the Continuous</a></li>
<li class="chapter" data-level="2.1.2" data-path="continuous-variables-and-eliciting-probability-distributions.html"><a href="continuous-variables-and-eliciting-probability-distributions.html#elicitation"><i class="fa fa-check"></i><b>2.1.2</b> Elicitation</a></li>
<li class="chapter" data-level="2.1.3" data-path="continuous-variables-and-eliciting-probability-distributions.html"><a href="continuous-variables-and-eliciting-probability-distributions.html#conjugacy"><i class="fa fa-check"></i><b>2.1.3</b> Conjugacy</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="three-conjugate-families.html"><a href="three-conjugate-families.html"><i class="fa fa-check"></i><b>2.2</b> Three Conjugate Families</a><ul>
<li class="chapter" data-level="2.2.1" data-path="three-conjugate-families.html"><a href="three-conjugate-families.html#inference-on-a-binomial-proportion"><i class="fa fa-check"></i><b>2.2.1</b> Inference on a Binomial Proportion</a></li>
<li class="chapter" data-level="2.2.2" data-path="three-conjugate-families.html"><a href="three-conjugate-families.html#the-gamma-poisson-conjugate-families"><i class="fa fa-check"></i><b>2.2.2</b> The Gamma-Poisson Conjugate Families</a></li>
<li class="chapter" data-level="2.2.3" data-path="three-conjugate-families.html"><a href="three-conjugate-families.html#the-normal-normal-conjugate-families"><i class="fa fa-check"></i><b>2.2.3</b> The Normal-Normal Conjugate Families</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="credible-intervals-and-predictive-inference.html"><a href="credible-intervals-and-predictive-inference.html"><i class="fa fa-check"></i><b>2.3</b> Credible Intervals and Predictive Inference</a><ul>
<li class="chapter" data-level="2.3.1" data-path="credible-intervals-and-predictive-inference.html"><a href="credible-intervals-and-predictive-inference.html#non-conjugate-priors"><i class="fa fa-check"></i><b>2.3.1</b> Non-Conjugate Priors</a></li>
<li class="chapter" data-level="2.3.2" data-path="credible-intervals-and-predictive-inference.html"><a href="credible-intervals-and-predictive-inference.html#credible-intervals"><i class="fa fa-check"></i><b>2.3.2</b> Credible Intervals</a></li>
<li class="chapter" data-level="2.3.3" data-path="credible-intervals-and-predictive-inference.html"><a href="credible-intervals-and-predictive-inference.html#predictive-inference"><i class="fa fa-check"></i><b>2.3.3</b> Predictive Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="losses-and-decision-making.html"><a href="losses-and-decision-making.html"><i class="fa fa-check"></i><b>3</b> Losses and Decision-making</a><ul>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="losses-and-decision-making-1.html"><a href="losses-and-decision-making-1.html"><i class="fa fa-check"></i><b>3.2</b> Losses and Decision Making</a></li>
<li class="chapter" data-level="3.3" data-path="working-with-loss-functions.html"><a href="working-with-loss-functions.html"><i class="fa fa-check"></i><b>3.3</b> Working with Loss Functions</a></li>
<li class="chapter" data-level="3.4" data-path="minimizing-expectated-loss-for-hypothesis-testing.html"><a href="minimizing-expectated-loss-for-hypothesis-testing.html"><i class="fa fa-check"></i><b>3.4</b> Minimizing Expectated Loss for Hypothesis Testing</a></li>
<li class="chapter" data-level="3.5" data-path="posterior-probabilities-of-hypotheses-and-bayes-factors.html"><a href="posterior-probabilities-of-hypotheses-and-bayes-factors.html"><i class="fa fa-check"></i><b>3.5</b> Posterior Probabilities of Hypotheses and Bayes Factors</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inference-for-multiple-parameters.html"><a href="inference-for-multiple-parameters.html"><i class="fa fa-check"></i><b>4</b> Inference for Multiple Parameters</a><ul>
<li class="chapter" data-level="4.1" data-path="conjugate-prior-for-normal-population-with-unknown-mean-and-variance.html"><a href="conjugate-prior-for-normal-population-with-unknown-mean-and-variance.html"><i class="fa fa-check"></i><b>4.1</b> Conjugate Prior for Normal Population with Unknown Mean and Variance</a></li>
<li class="chapter" data-level="4.2" data-path="monte-carlo-simulation.html"><a href="monte-carlo-simulation.html"><i class="fa fa-check"></i><b>4.2</b> Monte Carlo Simulation</a></li>
<li class="chapter" data-level="4.3" data-path="predictive-distributions.html"><a href="predictive-distributions.html"><i class="fa fa-check"></i><b>4.3</b> Predictive Distributions</a></li>
<li class="chapter" data-level="4.4" data-path="beyond-conjugate-priors.html"><a href="beyond-conjugate-priors.html"><i class="fa fa-check"></i><b>4.4</b> Beyond Conjugate Priors</a></li>
<li class="chapter" data-level="4.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>4.5</b> Markov Chain Monte Carlo</a></li>
<li class="chapter" data-level="4.6" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-testing-for-one-and-two-normal-samples.html"><a href="hypothesis-testing-for-one-and-two-normal-samples.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Testing for One and Two Normal Samples</a><ul>
<li class="chapter" data-level="5.1" data-path="bayes-factors-for-testing-a-normal-mean-variance-known.html"><a href="bayes-factors-for-testing-a-normal-mean-variance-known.html"><i class="fa fa-check"></i><b>5.1</b> Bayes Factors for Testing a Normal Mean: Variance Known</a></li>
<li class="chapter" data-level="5.2" data-path="bayes-factors-for-testing-a-normal-mean-variance-unknown.html"><a href="bayes-factors-for-testing-a-normal-mean-variance-unknown.html"><i class="fa fa-check"></i><b>5.2</b> Bayes Factors for Testing a Normal Mean: Variance Unknown</a></li>
<li class="chapter" data-level="5.3" data-path="bayes-factors-for-hypotheses-about-means-in-two-groups.html"><a href="bayes-factors-for-hypotheses-about-means-in-two-groups.html"><i class="fa fa-check"></i><b>5.3</b> Bayes Factors for Hypotheses about Means in Two Groups</a></li>
<li class="chapter" data-level="5.4" data-path="credible-intervals-after-hypothesis-testing.html"><a href="credible-intervals-after-hypothesis-testing.html"><i class="fa fa-check"></i><b>5.4</b> Credible Intervals after Hypothesis Testing</a></li>
<li class="chapter" data-level="5.5" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="frequentist-vs.bayesian-inference" class="section level2">
<h2><span class="header-section-number">1.3</span> Frequentist vs. Bayesian Inference</h2>
<div id="frequentist-vs.bayesian-inference-1" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Frequentist vs. Bayesian Inference</h3>
<p>In this section, we will solve a simple inference problem using both frequentist and Bayesian approaches. Then we will compare our results based on decisions based on the two methods, to see whether we get the same answer or not. If we do not, we will discuss why that happens.</p>

<div class="example">
<p><span id="ex:MM" class="example"><strong>Example 1.9 </strong></span>We have a population of M&amp;M’s, and in this population the percentage of yellow M&amp;M’s is either 10% or 20%. You’ve been hired as a statistical consultant to decide whether the true percentage of yellow M&amp;M’s is 10% or 20%.</p>
<p>Payoffs/losses: You are being asked to make a decision, and there are associated payoff/losses that you should consider. If you make the correct decision, your boss gives you a bonus. On the other hand, if you make the wrong decision, you lose your job.</p>
<p>Data: You can “buy” a random sample from the population – You pay $200 for each M&amp;M, and you must buy in $1,000 increments (5 M&amp;Ms at a time). You have a total of $4,000 to spend, i.e., you may buy 5, 10, 15, or 20 M&amp;Ms.</p>
Remark: Remember that the cost of making a wrong decision is high, so you want to be fairly confident of your decision. At the same time, though, data collection is also costly, so you don’t want to pay for a sample larger than you need. If you believe that you could actually make a correct decision using a smaller sample size, you might choose to do so and save money and resources.
</div>
<p></p>
<p>Let’s start with the frequentist inference.</p>
<ul>
<li><p>Hypothesis: <span class="math inline">\(H_0\)</span> is 10% yellow M&amp;Ms, and <span class="math inline">\(H_A\)</span> is &gt;10% yellow M&amp;Ms.</p></li>
<li><p>Significance level: <span class="math inline">\(\alpha = 0.05\)</span>.</p></li>
<li><p>Sample: red, green, <strong>yellow</strong>, blue, orange</p></li>
<li><p>Observed data: <span class="math inline">\(k=1, n=5\)</span></p></li>
<li><p>P-value: <span class="math inline">\(P(k \geq 1 | n=5, p=0.10) = 1 - P(k=0 | n=5, p=0.10) = 1 - 0.90^5 \approx 0.41\)</span></p></li>
</ul>
<p>Note that the p-value is the probability of observed or more extreme outcome given that the null hypothesis is true.</p>
<p>Therefore, we fail to reject <span class="math inline">\(H_0\)</span> and conclude that the data do not provide convincing evidence that the proportion of yellow M&amp;M’s is greater than 10%. This means that if we had to pick between 10% and 20% for the proportion of M&amp;M’s, even though this hypothesis testing procedure does not actually confirm the null hypothesis, we would likely stick with 10% since we couldn’t find evidence that the proportion of yellow M&amp;M’s is greater than 10%.</p>
<p>The Bayesian inference works differently as below.</p>
<ul>
<li><p>Hypotheses: <span class="math inline">\(H_1\)</span> is 10% yellow M&amp;Ms, and <span class="math inline">\(H_2\)</span> is 20% yellow M&amp;Ms.</p></li>
<li><p>Prior: <span class="math inline">\(P(H_1) = P(H_2) = 0.5\)</span></p></li>
<li><p>Sample: red, green, <strong>yellow</strong>, blue, orange</p></li>
<li><p>Observed data: <span class="math inline">\(k=1, n=5\)</span></p></li>
<li><p>Likelihood:</p></li>
</ul>
<p><span class="math display">\[\begin{align}
P(k=1 | H_1) &amp;= \left( \begin{array}{c} 5 \\ 1 \end{array} \right) \times 0.10 \times 0.90^4 \approx 0.33 \\
P(k=1 | H_2) &amp;= \left( \begin{array}{c} 5 \\ 1 \end{array} \right) \times 0.20 \times 0.80^4 \approx 0.41
\end{align}\]</span></p>
<ul>
<li>Posterior</li>
</ul>
<p><span class="math display">\[\begin{align}
P(H_1 | k=1) &amp;= \frac{P(H_1)P(k=1 | H_1)}{P(k=1)} = \frac{0.5 \times 0.33}{0.5 \times 0.33 + 0.5 \times 0.41} \approx 0.45 \\
P(H_2 | k=1) &amp;= 1 - 0.45 = 0.55
\end{align}\]</span></p>
<p>The posterior probabilities of whether <span class="math inline">\(H_1\)</span> or <span class="math inline">\(H_2\)</span> is correct are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with a strong confidence, given the observed data. However, <span class="math inline">\(H_2\)</span> has a higher posterior probability than <span class="math inline">\(H_1\)</span>, so if we had to make a decision at this point, we should pick <span class="math inline">\(H_2\)</span>, i.e., the proportion of yellow M&amp;Ms is 20%. Note that this decision contradicts with the decision based on the frequentist approach.</p>
<p>Table <a href="frequentist-vs-bayesian-inference.html#tab:freq-vs-bayes">1.3</a> summarizes what the results would look like if we had chosen larger sample sizes. Under each of these scenarios, the frequentist method yields a higher p-value than our significance level, so we would fail to reject the null hypothesis with any of these samples. On the other hand, the Bayesian method always yields a higher posterior for the second model where <span class="math inline">\(p\)</span> is equal to 0.20. So the decisions that we would make are contradictory to each other.</p>
<table>
<caption><span id="tab:freq-vs-bayes">Table 1.3: </span>Frequentist and Bayesian probabilities for larger sample sizes</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Frequentist</th>
<th align="left">Bayesian H_1</th>
<th align="left">Bayesian H_2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Observed Data</td>
<td align="left">P(k or more | 10% yellow)</td>
<td align="left">P(10% yellow | n, k)</td>
<td align="left">P(20% yellow | n, k)</td>
</tr>
<tr class="even">
<td>n = 5, k = 1</td>
<td align="left">0.41</td>
<td align="left">0.45</td>
<td align="left">0.55</td>
</tr>
<tr class="odd">
<td>n = 10, k = 2</td>
<td align="left">0.26</td>
<td align="left">0.39</td>
<td align="left">0.61</td>
</tr>
<tr class="even">
<td>n = 15, k = 3</td>
<td align="left">0.18</td>
<td align="left">0.34</td>
<td align="left">0.66</td>
</tr>
<tr class="odd">
<td>n = 20, k = 4</td>
<td align="left">0.13</td>
<td align="left">0.29</td>
<td align="left">0.71</td>
</tr>
</tbody>
</table>
<p>However, if we had set up our framework differently in the frequentist method and set our null hypothesis to be <span class="math inline">\(p = 0.20\)</span> and our alternative to be <span class="math inline">\(p &lt; 0.20\)</span>, we would obtain different results. This shows that <strong>the frequentist method is highly sensitive to the null hypothesis</strong>, while in the Bayesian method, our results would be the same regardless of which order we evaluate our models.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inference-for-a-proportion.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exercises.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-basics-03-freq-vs-bayes.Rmd",
"text": "Edit"
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
