<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Bayesian Statistics</title>
  <meta name="description" content="This book is a written companion for the Course Course ‘Bayesian Statistics’ from the Statistics with R specialization.">
  <meta name="generator" content="bookdown <!--bookdown:version--> and GitBook 2.6.7">

  <meta property="og:title" content="Bayesian Statistics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://www.coursera.org/learn/bayesian/home/info/" />
  <meta property="og:image" content="http://www.coursera.org/learn/bayesian/home/info/cover.png" />
  <meta property="og:description" content="This book is a written companion for the Course Course ‘Bayesian Statistics’ from the Statistics with R specialization." />
  <meta name="github-repo" content="StatsWithR/book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bayesian Statistics" />
  
  <meta name="twitter:description" content="This book is a written companion for the Course Course ‘Bayesian Statistics’ from the Statistics with R specialization." />
  <meta name="twitter:image" content="http://www.coursera.org/learn/bayesian/home/info/cover.png" />

<meta name="author" content="Christine Chai">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Bayesian Statistics</h1>
<h3 class="subtitle"><em>A Companion to the Statistics with R Coursera Course</em></h3>
<h4 class="author"><em>Christine Chai</em></h4>
<h4 class="date"><em>Last built on 2017-08-07</em></h4>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#the-basics-of-bayesian-statistics"><span class="toc-section-number">1</span> The Basics of Bayesian Statistics</a><ul>
<li><a href="#bayes-rule"><span class="toc-section-number">1.1</span> Bayes’ Rule</a><ul>
<li><a href="#sec:bayes-rule"><span class="toc-section-number">1.1.1</span> Conditional Probabilities &amp; Bayes’ Rule</a></li>
<li><a href="#diagnostic-testing"><span class="toc-section-number">1.1.2</span> Bayes’ Rule and Diagnostic Testing</a></li>
<li><a href="#bayes-updating"><span class="toc-section-number">1.1.3</span> Bayes Updating</a></li>
<li><a href="#bayesian-vs.frequentist-definitions-of-probability"><span class="toc-section-number">1.1.4</span> Bayesian vs. Frequentist Definitions of Probability</a></li>
</ul></li>
<li><a href="#inference-for-a-proportion"><span class="toc-section-number">1.2</span> Inference for a Proportion</a><ul>
<li><a href="#inference-for-a-proportion-frequentist-approach"><span class="toc-section-number">1.2.1</span> Inference for a Proportion: Frequentist Approach</a></li>
<li><a href="#inference-for-a-proportion-bayesian-approach"><span class="toc-section-number">1.2.2</span> Inference for a Proportion: Bayesian Approach</a></li>
<li><a href="#effect-of-sample-size-on-the-posterior"><span class="toc-section-number">1.2.3</span> Effect of Sample Size on the Posterior</a></li>
</ul></li>
<li><a href="#frequentist-vs.bayesian-inference"><span class="toc-section-number">1.3</span> Frequentist vs. Bayesian Inference</a><ul>
<li><a href="#frequentist-vs.bayesian-inference-1"><span class="toc-section-number">1.3.1</span> Frequentist vs. Bayesian Inference</a></li>
</ul></li>
<li><a href="#exercises"><span class="toc-section-number">1.4</span> Exercises</a></li>
</ul></li>
<li><a href="#bayesian-inference"><span class="toc-section-number">2</span> Bayesian Inference</a><ul>
<li><a href="#continuous-variables-and-eliciting-probability-distributions"><span class="toc-section-number">2.1</span> Continuous Variables and Eliciting Probability Distributions</a><ul>
<li><a href="#from-the-discrete-to-the-continuous"><span class="toc-section-number">2.1.1</span> From the Discrete to the Continuous</a></li>
<li><a href="#elicitation"><span class="toc-section-number">2.1.2</span> Elicitation</a></li>
<li><a href="#conjugacy"><span class="toc-section-number">2.1.3</span> Conjugacy</a></li>
</ul></li>
<li><a href="#three-conjugate-families"><span class="toc-section-number">2.2</span> Three Conjugate Families</a><ul>
<li><a href="#inference-on-a-binomial-proportion"><span class="toc-section-number">2.2.1</span> Inference on a Binomial Proportion</a></li>
<li><a href="#the-gamma-poisson-conjugate-families"><span class="toc-section-number">2.2.2</span> The Gamma-Poisson Conjugate Families</a></li>
<li><a href="#sec:normal-normal"><span class="toc-section-number">2.2.3</span> The Normal-Normal Conjugate Families</a></li>
</ul></li>
<li><a href="#credible-intervals-and-predictive-inference"><span class="toc-section-number">2.3</span> Credible Intervals and Predictive Inference</a><ul>
<li><a href="#non-conjugate-priors"><span class="toc-section-number">2.3.1</span> Non-Conjugate Priors</a></li>
<li><a href="#credible-intervals"><span class="toc-section-number">2.3.2</span> Credible Intervals</a></li>
<li><a href="#predictive-inference"><span class="toc-section-number">2.3.3</span> Predictive Inference</a></li>
</ul></li>
</ul></li>
<li><a href="#losses-and-decision-making"><span class="toc-section-number">3</span> Losses and Decision-making</a><ul>
<li><a href="#introduction"><span class="toc-section-number">3.1</span> Introduction</a></li>
<li><a href="#losses-and-decision-making-1"><span class="toc-section-number">3.2</span> Losses and Decision Making</a></li>
<li><a href="#working-with-loss-functions"><span class="toc-section-number">3.3</span> Working with Loss Functions</a></li>
<li><a href="#minimizing-expectated-loss-for-hypothesis-testing"><span class="toc-section-number">3.4</span> Minimizing Expectated Loss for Hypothesis Testing</a></li>
<li><a href="#posterior-probabilities-of-hypotheses-and-bayes-factors"><span class="toc-section-number">3.5</span> Posterior Probabilities of Hypotheses and Bayes Factors</a></li>
</ul></li>
<li><a href="#inference-for-multiple-parameters"><span class="toc-section-number">4</span> Inference for Multiple Parameters</a><ul>
<li><a href="#sec:normal-gamma"><span class="toc-section-number">4.1</span> Inference for Normal Mean with Unknown Variance</a><ul>
<li><a href="#sampling-model"><span class="toc-section-number">4.1.1</span> Sampling Model</a></li>
<li><a href="#conjugate-prior"><span class="toc-section-number">4.1.2</span> Conjugate prior</a></li>
<li><a href="#posterior-distribution"><span class="toc-section-number">4.1.3</span> Posterior Distribution</a></li>
<li><a href="#marginal-distribution-for-mu"><span class="toc-section-number">4.1.4</span> Marginal Distribution for <span class="math inline">\(\mu\)</span></a></li>
</ul></li>
<li><a href="#monte-carlo-simulation"><span class="toc-section-number">4.2</span> Monte Carlo Simulation</a></li>
<li><a href="#predictive-distributions"><span class="toc-section-number">4.3</span> Predictive Distributions</a></li>
<li><a href="#reference-priors"><span class="toc-section-number">4.4</span> Reference Priors</a></li>
<li><a href="#beyond-conjugate-priors-using-mixtures"><span class="toc-section-number">4.5</span> Beyond Conjugate Priors using Mixtures</a></li>
<li><a href="#markov-chain-monte-carlo"><span class="toc-section-number">4.6</span> Markov Chain Monte Carlo</a></li>
<li><a href="#excercises"><span class="toc-section-number">4.7</span> Excercises</a></li>
</ul></li>
<li><a href="#hypothesis-testing-for-one-and-two-normal-samples"><span class="toc-section-number">5</span> Hypothesis Testing for One and Two Normal Samples</a><ul>
<li><a href="#bayes-factors-for-testing-a-normal-mean-variance-known"><span class="toc-section-number">5.1</span> Bayes Factors for Testing a Normal Mean: Variance Known</a></li>
<li><a href="#bayes-factors-for-testing-a-normal-mean-variance-unknown"><span class="toc-section-number">5.2</span> Bayes Factors for Testing a Normal Mean: Variance Unknown</a></li>
<li><a href="#bayes-factors-for-hypotheses-about-means-in-two-groups"><span class="toc-section-number">5.3</span> Bayes Factors for Hypotheses about Means in Two Groups</a></li>
<li><a href="#credible-intervals-after-hypothesis-testing"><span class="toc-section-number">5.4</span> Credible Intervals after Hypothesis Testing</a></li>
<li><a href="#exercises-1"><span class="toc-section-number">5.5</span> Exercises</a></li>
</ul></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<p>  0{n_0}   # Welcome {-}</p>
<p>This book is a written companion for the Coursera Course ‘Bayesian Statistics’ from the Statistics with R specialization. Materials and examples from the course are discussed more extensively and extra examples and exercises are provided.</p>
<!--chapter:end:index.Rmd-->
<div id="the-basics-of-bayesian-statistics" class="section level1">
<h1><span class="header-section-number">1</span> The Basics of Bayesian Statistics</h1>
<p>Bayesian statistics mostly involves <strong>conditional probability</strong>, which is the the probability of an event A given event B, and it can be calculated using the Bayes’ rule. The concept of conditional probability is widely used in medical testing, in which false positives and false negatives may occur. A false positive can be defined as a positive outcome on a medical test when the patient does not actually have the disease they are being tested for. In other words, it’s the probability of testing positive given no disease. Similarly, a false negative can be defined as a negative outcome on a medical test when the patient does have the disease. In other words, testing negative given disease. Both indicators are critical for any medical decisions.</p>
<p>For how the Bayes’ rule is applied, we can set up a prior, then calculate posterior probabilities based on a prior and likelihood. That is to say, the prior probabilities are updated through an iterative process of data collection.</p>
<!--chapter:end:01-basics-00-intro.Rmd-->
<div id="bayes-rule" class="section level2">
<h2><span class="header-section-number">1.1</span> Bayes’ Rule</h2>
<p>NEED INTRO TEXT OTHERWISE LABEL MULTIPLIED DEFINED IN LATEX/PDF</p>
<div id="sec:bayes-rule" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Conditional Probabilities &amp; Bayes’ Rule</h3>
<p>Consider Table @ref(tab:2015gallupDating). It shows the results of a poll among 1738 adult Americans. This table allows us to calculate probabilities.</p>
<table>
<caption>(#tab:2015gallupDating)Results from a 2015 Gallup poll on the use of online dating sites by age group</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">18-29</th>
<th align="right">30-49</th>
<th align="right">50-64</th>
<th align="right">65+</th>
<th align="right">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Used online dating site</td>
<td align="right">60</td>
<td align="right">86</td>
<td align="right">58</td>
<td align="right">21</td>
<td align="right">225</td>
</tr>
<tr class="even">
<td>Did not use online dating site</td>
<td align="right">255</td>
<td align="right">426</td>
<td align="right">450</td>
<td align="right">382</td>
<td align="right">1513</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="right">316</td>
<td align="right">512</td>
<td align="right">508</td>
<td align="right">403</td>
<td align="right">1738</td>
</tr>
</tbody>
</table>
For instance, the probability of an adult American using an online dating site can be calculated as
<span class="math display">\[\begin{multline*}
    P(\text{using an online dating site}) = \\
    \frac{\text{Number that indicated they used an online dating site}}{\text{Total number of people in the poll}}
    = \frac{225}{1738} \approx 13\%.
\end{multline*}\]</span>
This is the overall probability of using an online dating site. Say, we are now interested in the probability of using an online dating site if one falls in the age group 30-49. Similar to the above, we have
<span class="math display">\[\begin{multline*}
    P(\text{using an online dating site} \mid \text{in age group 30-49}) = \\
    \frac{\text{Number in age group 30-49 that indicated they used an online dating site}}{\text{Total number in age group 30-49}}
    = \frac{86}{512} \approx 17\%.
\end{multline*}\]</span>
<p>Here, the pipe symbol `|’ means <em>conditional on</em>. This is a <em>conditional probability</em> as one can consider it the probability of using an online dating site conditional on being in age group 30-49.</p>
We can rewrite this conditional probability in terms of ‘regular’ probabilities by dividing both numerator and the denominator by the total number of people in the poll. That is,
<span class="math display">\[\begin{multline*}
    P(\text{using an online dating site} \mid \text{in age group 30-49}) \\
\begin{split}
    &amp;= \frac{\text{Number in age group 30-49 that indicated they used an online dating site}}{\text{Total number in age group 30-49}} \\
    &amp;= \frac{\frac{\text{Number in age group 30-49 that indicated they used an online dating site}}{\text{Total number of people in the poll}}}{\frac{\text{Total number in age group 30-49}}{\text{Total number of people in the poll}}} \\
    &amp;= \frac{P(\text{using an online dating site \&amp; falling in age group 30-49})}{P(\text{Falling in age group 30-49})}.
\end{split}
\end{multline*}\]</span>
<p>It turns out this relationship holds true for any conditional probability and is known as Bayes’ rule:</p>

<div class="definition">
<p><span id="def:unnamed-chunk-1" class="definition"><strong>(#def:unnamed-chunk-1) (Bayes’ Rule)  </strong></span>The conditional probability of the event <span class="math inline">\(A\)</span> conditional on the event <span class="math inline">\(B\)</span> is given by</p>
<span class="math display">\[
  P(A \mid B) = \frac{P(A \,\&amp;\, B)}{P(B)}.
\]</span>
</div>
<p></p>

<div class="example">
<p><span id="ex:unnamed-chunk-2" class="example"><strong>(#ex:unnamed-chunk-2)</strong></span>What is the probability that an 18-29 year old from Table @ref(tab:2015gallupDating) uses online dating sites?</p>
<p>Note that the question asks a question about 18-29 year olds. Therefore, it conditions on being 18-29 years old. Bayes’ rule provides a way to compute this conditional probability:</p>
<span class="math display">\[\begin{multline*}
    P(\text{using an online dating site} \mid \text{in age group 18-29}) \\
\begin{split}
    &amp;= \frac{P(\text{using an online dating site \&amp; falling in age group 18-29})}{P(\text{Falling in age group 18-29})} \\
    &amp;= \frac{\frac{\text{Number in age group 18-29 that indicated they used an online dating site}}{\text{Total number of people in the poll}}}{\frac{\text{Total number in age group 18-29}}{\text{Total number of people in the poll}}} \\
    &amp;= \frac{\text{Number in age group 18-29 that indicated they used an online dating site}}{\text{Total number in age group 18-29}} = \frac{60}{315} \approx 19\%.
\end{split}
\end{multline*}\]</span>
</div>
<p></p>
</div>
<div id="diagnostic-testing" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Bayes’ Rule and Diagnostic Testing</h3>
<p>To better understand conditional probabilities and their importance, let us consider an example involving the human immunodeficiency virus (HIV). In the early 1980s, HIV had just been discovered and was rapidly expanding. There was major concern with the safety of the blood supply. Also, virtually no cure existed making an HIV diagnosis basically a death sentence, in addition to the stigma that was attached to the disease.</p>
<p>These made false positives and false negatives in HIV testing highly undesirable. A <em>false positive</em> is when a test returns postive while the truth is negative. That would for instance be that someone without HIV is wrongly diagnosed with HIV, wrongly telling that person they are going to die and casting the stigma on them. A <em>false negative</em> is when a test returns negative while the truth is positive. That is when someone with HIV undergoes an HIV test which wrongly comes back negative. The latter poses a threat to the blood supply if that person is about to donate blood.</p>
<p>The probability of a false positive if the truth is negative is called the false positive rate. Similarly, the false negative rate is the probability of a false negative if the truth is positive. Note that both these rates are conditional probabilities: The false positive rate of an HIV test is the probability of a positive result <em>conditional on</em> the person tested having no HIV.</p>
The HIV test we consider is an enzyme-linked immunosorbent assay, commonly known as an ELISA. We would like to know the probability that someone (in the early 1980s) has HIV if ELISA tests positive. For this, we need the following information. ELISA’s true positive rate (one minus the false negative rate), also referred to as sensitivity, recall, or probability of detection, is estimated as <span class="math display">\[
  P(\text{ELISA is positive} \mid \text{Person tested has HIV}) = 93\% = 0.93.
\]</span> Its true negative rate (one minus the false positive rate), also referred to as specificity, is estimated as <span class="math display">\[
  P(\text{ELISA is negative} \mid \text{Person tested has no HIV}) = 99\% = 0.99.
\]</span> Also relevant to our question is the prevalence of HIV in the overall population, which is estimated to be 1.48 out of every 1000 American adults. We therefore assume
<span class="math display">\[\begin{equation}
  P(\text{Person tested has HIV}) = \frac{1.48}{1000} = 0.00148.
  (\#eq:HIVpositive)
\end{equation}\]</span>
<p>Note that the above numbers are estimates. For our purposes, however, we will treat them as if they were exact.</p>
Our goal is to compute the probability of HIV if ELISA is positive, that is <span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive})\)</span>. In none of the above numbers did we condition on the outcome of ELISA. Fortunately, Bayes’ rule allows is to use the above numbers to compute the probability we seek. Bayes’ rule states that <span class="math display">\[
\begin{aligned}
  P(\text{Person tested has HIV} \mid \text{ELISA is positive}) \\
  = \frac{P(\text{Person tested has HIV} \,\&amp;\, \text{ELISA is positive})}{P(\text{ELISA is positive})}.
\end{aligned}
(\#eq:HIVconditional)
\]</span> The can be derived as follows. For someone to test positive and be HIV positive, that person first needs to be HIV positive and then seconldy test positive. The probability of the first thing happening is <span class="math inline">\(P(\text{HIV positive}) = 0.00148\)</span>. The probability of then testing positive is <span class="math inline">\(P(\text{ELISA is positive} \mid \text{Person tested has HIV}) = 0.93\)</span>, the true positive rate. This yields for the numerator
<span class="math display">\[\begin{multline*}
  P(\text{Person tested has HIV} \,\&amp;\, \text{ELISA is positive}) \\
  \begin{split}
  &amp;= P(\text{Person tested has HIV}) P(\text{ELISA is positive} \mid \text{Person tested has HIV}) \\
  &amp;= 0.00148 \cdot 0.93
  = 0.0013764.
  \end{split}
  (\#eq:HIVjoint)
\end{multline*}\]</span>
<p>The first step in the above equation is implied by Bayes’ rule: By multiplying the left- and right-hand side of Bayes’ rule as presented in Section @ref(sec:bayes-rule) by <span class="math inline">\(P(B)\)</span>, we obtain <span class="math display">\[
  P(A \mid B) P(B) = P(A \,\&amp;\, B).
\]</span></p>
The denominator in @ref(eq:HIVconditional) can be expanded as
<span class="math display">\[\begin{multline*}
  P(\text{ELISA is positive}) \\
  \begin{split}
  &amp;= P(\text{Person tested has HIV} \,\&amp;\, \text{ELISA is positive})
  + P(\text{Person tested has no HIV} \,\&amp;\, \text{ELISA is positive}) \\
  &amp;= 0.0013764 + 0.0099852 = 0.0113616
  \end{split}
\end{multline*}\]</span>
where we used @ref(eq:HIVjoint) and
<span class="math display">\[\begin{multline*}
  P(\text{Person tested has no HIV} \,\&amp;\, \text{ELISA is positive}) \\
  = P(\text{Person tested has no HIV}) P(\text{ELISA is positive} \mid \text{Person tested has no HIV})
  = \left(1 - P(\text{Person tested has HIV})\right) \cdot \left(1 - P(\text{ELISA is negative} \mid \text{Person tested has no HIV})\right)
  = \left(1 - 0.00148\right) \cdot \left(1 - 0.99\right) = 0.0099852.
\end{multline*}\]</span>
Putting this all together and inserting into @ref(eq:HIVconditional) reveals
<span class="math display">\[\begin{equation}
  P(\text{Person tested has HIV} \mid \text{ELISA is positive}) = \frac{0.0013764}{0.0113616} \approx 0.12.
  (\#eq:HIVresult)
\end{equation}\]</span>
<p>So even when the ELISA returns positive, the probability of having HIV is only 12%. An important reason why this number is so low is due to the prevalence of HIV. Before testing, one’s probability of HIV was 0.148%, so the positive test changes that probability dramatically, but it is still below 50%. That is, it is more likely that one is HIV negative rather than positive after one positive ELISA test.</p>
<p>Questions like the one we just answered (What is the probability of a disease if a test returns positive?) are crucial to make medical diagnoses. As we saw, just the true positive and true negative rates of a test do not tell the full story, but also a disease’s prevalence plays a role. Bayes’ rule is a tool to synthesize such numbers into a more useful probability of having a disease after a test result.</p>
<p>If the an individual is at a higher risk for having HIV than a randomly sampled person from the population considered, how, if at all, would you expect <span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive})\)</span> to change?</p>

<div class="example">
<span id="ex:unnamed-chunk-3" class="example"><strong>(#ex:unnamed-chunk-3)</strong></span>What is the probability that someone who tests positive does not actually have HIV?
</div>
<p></p>
<p>We found in @ref(eq:HIVresult) that someone who tests positive has a <span class="math inline">\(0.12\)</span> probability of having HIV. That implies that the same person has a <span class="math inline">\(1-0.12=0.88\)</span> probability of not having HIV, despite testing positive.</p>

<div class="example">
<span id="ex:unnamed-chunk-4" class="example"><strong>(#ex:unnamed-chunk-4)</strong></span>If the an individual is at a higher risk for having HIV than a randomly sampled person from the population considered, how, if at all, would you expect <span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive})\)</span> to change?
</div>
<p></p>
<p>If the person has a priori a higher risk for HIV and tests positive, then the probability of having HIV must be higher than for someone not at increased risk who also tests positive. Therefore, <span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive}) &gt; 0.12\)</span> where <span class="math inline">\(0.12\)</span> comes from @ref(eq:HIVresult).</p>
<p>One can derive this mathematically by plugging in a larger number in @ref(eq:HIVpositive) than 0.00148, as that number represents the prior risk of HIV. Changing the calculations accordingly shows <span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive}) &gt; 0.12\)</span>.</p>

<div class="example">
<span id="ex:unnamed-chunk-5" class="example"><strong>(#ex:unnamed-chunk-5)</strong></span>If the false positive rate of the test is higher than 1%, how, if at all, would you expect <span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive})\)</span> to change?
</div>
<p></p>
<p>If the false positive rate increases, the probability of a wrong positive result increases. That means that a positive test result is more likely to be wrong and thus less indicative of HIV. Therefore, the probability of HIV after a positive ELISA goes down such that <span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive}) &lt; 0.12\)</span>.</p>
</div>
<div id="bayes-updating" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Bayes Updating</h3>
<p>In the previous section, we saw that one positive ELISA test yields a probability of having HIV of 12%. To obtain a more convincing probability, one might want to do a second ELISA test after a first one comes up positive. What is the probability of being HIV positive of also the second ELISA test comes back positive?</p>
<p>To solve this problem, we will assume that the correctness of this second test is not influenced by the first ELISA, that is, the tests are independent from each other. This assumption probably does not hold true as it is plausible that if the first test was a false positive, it is more likely that the second one will be one as well. Nonetheless, we stick with the independence assumption for simplicity.</p>
<p>In the last section, we used <span class="math inline">\(P(\text{Person tested has HIV}) = 0.00148\)</span>, see @ref(eq:HIVpositive), to compute the probability of HIV after one positive test. If we repeat those steps but now with <span class="math inline">\(P(\text{Person tested has HIV}) = 0.12\)</span>, the probability that a person with one positive test has HIV, we exactly obtain the probability of HIV after two positive tests. Repeating the maths from the previous section, involving Bayes’ rule, gives</p>
<span class="math display">\[\begin{multline*}
  P(\text{Person tested has HIV} \mid \text{Second ELISA is also positive}) \\
  \begin{split}
  &amp;= \frac{P(\text{Person tested has HIV}) P(\text{Second ELISA is positive} \mid \text{Person tested has HIV})}{P(\text{Second ELISA is also positive})} \\
  &amp;= \frac{0.12 \cdot 0.93}{
  \begin{split}
  &amp;P(\text{Person tested has HIV}) P(\text{Second ELISA is positive} \mid \text{Has HIV}) \\
  + &amp;P(\text{Person tested has no HIV}) P(\text{Second ELISA is positive} \mid \text{Has no HIV})
  \end{split}
  } \\
  &amp;= \frac{0.1116}{0.12 \cdot 0.93 + (1 - 0.12)\cdot (1 - 0.99)} \approx 0.93.
  \end{split}
  (\#eq:Bayes-updating)
\end{multline*}\]</span>
<p>Since we are considering the same ELISA test, we used the same true positive and true negative rates as in Section @ref(diagnostic-testing). We see that two positive tests makes it much more probable for someone to have HIV than when only one test comes up positive.</p>
<p>This process, of using Bayes’ rule to update a probability based on an event affecting it, is called Bayes’ updating. More generally, the what one tries to update can be considered ‘prior’ information, sometimes simply called the <em>prior</em>. The event providing information about this can also be data. Then, updating this prior using Bayes’ rule gives the information conditional on the data, also known as the <em>posterior</em>, as in the information <em>after</em> having seen the data. Going from the prior to the posterior is Bayes updating.</p>
<p>The probability of HIV after one positive ELISA, 0.12, was the posterior in the previous section as it was an update of the overall prevalence of HIV, @ref(eq:HIVpositive). However, in this section we answered a question where we used this posterior information as the prior. This process of using a posterior as prior in a new problem is natural in the Bayesian framework of updating knowledge based on the data.</p>

<div class="example">
<span id="ex:unnamed-chunk-6" class="example"><strong>(#ex:unnamed-chunk-6)</strong></span>What is the probability that one actually has HIV after testing positive 3 times on the ELISA? Again, assume that all three ELISAs are independent.
</div>
<p></p>
Analogous to what we did in this section, we can use Bayes’ updating for this. However, now the prior is the probability of HIV after two positive ELISAs, that is <span class="math inline">\(P(\text{Person tested has HIV}) = 0.93\)</span>. Analogous to @ref(eq:Bayes-updating), the answer follows as
<span class="math display">\[\begin{multline*}
  P(\text{Person tested has HIV} \mid \text{Third ELISA is also positive}) \\
  \begin{split}
  &amp;= \frac{P(\text{Person tested has HIV}) P(\text{Third ELISA is positive} \mid \text{Person tested has HIV})}{P(\text{Third ELISA is also positive})} \\
  &amp;= \frac{0.93 \cdot 0.93}{\begin{split}
  &amp;P(\text{Person tested has HIV}) P(\text{Third ELISA is positive} \mid \text{Has HIV}) \\
  + &amp;P(\text{Person tested has no HIV}) P(\text{Third ELISA is positive} \mid \text{Has no HIV})
  \end{split}} \\
  &amp;= \frac{0.8649}{0.93 \cdot 0.93 + (1 - 0.93)\cdot (1 - 0.99)} \approx 0.999.
  \end{split}
\end{multline*}\]</span>
</div>
<div id="bayesian-vs.frequentist-definitions-of-probability" class="section level3">
<h3><span class="header-section-number">1.1.4</span> Bayesian vs. Frequentist Definitions of Probability</h3>
The frequentist definition of probability is based on observation of a large number of trials. The probability for an event <span class="math inline">\(E\)</span> to occur is <span class="math inline">\(P(E)\)</span>, and assume we get <span class="math inline">\(n_E\)</span> successes out of <span class="math inline">\(n\)</span> trials. Then we have
<span class="math display">\[\begin{equation}
P(E) = \lim_{n \rightarrow \infty} \dfrac{n_E}{n}.
\end{equation}\]</span>
<p>On the other hand, the Bayesian definition of probability <span class="math inline">\(P(E)\)</span> reflects our prior beliefs, so <span class="math inline">\(P(E)\)</span> can be any probability distribution, provided that it is consistent with all of our beliefs. (For example, we cannot believe that the probability of a coin landing heads is 0.7 and that the probability of getting tails is 0.8, because they are inconsistent.)</p>
<p>The two definitions result in different methods of inference. Using the frequentist approach, we describe the confidence level as the proportion of random samples from the same population that produced confidence intervals which contain the true population parameter. For example, if we generated 100 random samples from the population, and 95 of the samples contain the true parameter, then the confidence level is 95%. Note that each sample either contains the true parameter or does not, so the confidence level is NOT the probability that a given interval includes the true population parameter.</p>

<div class="example">
<span id="ex:unnamed-chunk-7" class="example"><strong>(#ex:unnamed-chunk-7)</strong></span>Based on a 2015 Pew Research poll on 1,500 adults: “We are 95% confident that 60% to 64% of Americans think the federal government does not do enough for middle class people.
</div>
<p></p>
<p>The correct interpretation is: 95% of random samples of 1,500 adults will produce confidence intervals that contain the true proportion of Americans who think the federal government does not do enough for middle class people.</p>
<p>Here are two common misconceptions:</p>
<ul>
<li><p>There is a 95% chance that this confidence interval includes the true population proportion.</p></li>
<li><p>The true population proportion is in this interval 95% of the time.</p></li>
</ul>
<p>The probability that a given confidence interval captures the true parameter is either zero or one. To a frequentist, the problem is that one never knows whether a specific interval contains the true value with probability zero or one. So a frequentist says that “95% of similarly constructed intervals contain the true value”.</p>
<p>The second (incorrect) statement sounds like the true proportion is a value that moves around that is sometimes in the given interval and sometimes not in it. Actually the true proportion is constant, it’s the various intervals constructed based on new samples that are different.</p>
<p>The Bayesian alternative is the credible interval, which has a definition that is easier to interpret. Since a Bayesian is allowed to express uncertainty in terms of probability, a Bayesian credible interval is a range for which the Bayesian thinks that the probability of including the true value is, say, 0.95. Thus a Bayesian can say that there is a 95% chance that the credible interval contains the true parameter value.</p>

<div class="example">
<span id="ex:unnamed-chunk-8" class="example"><strong>(#ex:unnamed-chunk-8)</strong></span>The posterior distribution yields a 95% credible interval of 60% to 64% for the proportion of Americans who think the federal government does not do enough for middle class people.
</div>
<p></p>
<p>We can say that there is a 95% probability that the proportion is between 60% and 64% because this is a <strong>credible</strong> interval, and more details will be introduced later in the course.</p>
<!--chapter:end:01-basics-01-bayes-rule.Rmd-->
</div>
</div>
<div id="inference-for-a-proportion" class="section level2">
<h2><span class="header-section-number">1.2</span> Inference for a Proportion</h2>
<div id="inference-for-a-proportion-frequentist-approach" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Inference for a Proportion: Frequentist Approach</h3>

<div class="example">
<p><span id="ex:RU-486" class="example"><strong>(#ex:RU-486)</strong></span>RU-486 is claimed to be an effective “morning after” contraceptive pill, but is it really effective?</p>
<p>Data: A total of 40 women came to a health clinic asking for emergency contraception (usually to prevent pregnancy after unprotected sex). They were randomly assigned to RU-486 (treatment) or standard therapy (control), 20 in each group. In the treatment group, 4 out of 20 became pregnant. In the control group, the pregnancy rate is 16 out of 20.</p>
Question: How strongly do these data indicate that the treatment is more effective than the control?
</div>
<p></p>
<p>To simplify the framework, let’s make it a one proportion problem and just consider the 20 total pregnancies because the two groups have the same sample size. If the treatment and control are equally effective, then the probability that a pregnancy comes from the treatment group (<span class="math inline">\(p\)</span>) should be 0.5. If RU-486 is more effective, then the probability that a pregnancy comes from the treatment group (<span class="math inline">\(p\)</span>) should be less than 0.5.</p>
<p>Therefore, we can form the hypotheses as below:</p>
<ul>
<li><p><span class="math inline">\(p =\)</span> probability that a given pregnancy comes from the treatment group</p></li>
<li><p><span class="math inline">\(H_0: p = 0.5\)</span> (no difference, a pregnancy is equally likely to come from the treatment or control group)</p></li>
<li><p><span class="math inline">\(H_A: p &lt; 0.5\)</span> (treatment is more effective, a pregnancy is less likely to come from the treatment group)</p></li>
</ul>
<p>A p-value is needed to make an inference decision with the frequentist approach. The definition of p-value is the probability of observing something <em>at least</em> as extreme as the data, given that the null hypothesis (<span class="math inline">\(H_0\)</span>) is true. “More extreme” means in the direction of the alternative hypothesis (<span class="math inline">\(H_A\)</span>).</p>
<p>Since <span class="math inline">\(H_0\)</span> states that the probability of success (pregnancy) is 0.5, we can calculate the p-value from 20 independent Bernoulli trials where the probability of success is 0.5. The outcome of this experiment is 4 successes in 20 trials, so the goal is to obtain 4 or fewer successes in the 20 Bernoulli trials.</p>
<p>This probability can be calculated exactly from a binomial distribution with <span class="math inline">\(n=20\)</span> trials and success probability <span class="math inline">\(p=0.5\)</span>. Assume <span class="math inline">\(k\)</span> is the actual number of successes observed, the p-value is</p>
<p><span class="math display">\[P(k \leq 4) = P(k = 0) + P(k = 1) + P(k = 2) + P(k = 3) + P(k = 4)\]</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">dbinom</span>(<span class="dv">0</span>:<span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">p =</span> <span class="fl">0.5</span>))</code></pre></div>
<pre><code>## [1] 0.005908966</code></pre>
<p>According to <span class="math inline">\(\mathsf{R}\)</span>, the probability of getting 4 or fewer successes in 20 trials is 0.0059. Therefore, given that pregnancy is equally likely in the two groups, we get the chance of observing 4 or fewer preganancy in the treatment group is 0.0059. With such a small probability, we reject the null hypothesis and conclude that the data provide convincing evidence for the treatment being more effective than the control.</p>
</div>
<div id="inference-for-a-proportion-bayesian-approach" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Inference for a Proportion: Bayesian Approach</h3>
<p>This section uses the same example, but this time we make the inference for the proportion from a Bayesian approach. Recall that we still consider only the 20 total pregnancies, 4 of which come from the treatment group. The question we would like to answer is that how likely is for 4 pregnancies to occur in the treatment group. Also remember that if the treatment and control are equally effective, and the sample sizes for the two groups are the same, then the probability (<span class="math inline">\(p\)</span>) that the pregnancy comes from the treatment group is 0.5.</p>
<p>Within the Bayesian framework, we need to make some assumptions on the models which generated the data. First, <span class="math inline">\(p\)</span> is a probability, so it can take on any value between 0 and 1. However, let’s simplify by using discrete cases – assume <span class="math inline">\(p\)</span>, the chance of a pregnancy comes from the treatment group, can take on nine values, from 10%, 20%, 30%, up to 90%. For example, <span class="math inline">\(p = 20\%\)</span> means that among 10 pregnancies, it is expected that 2 of them will occur in the treatment group. Note that we consider all nine models, compared with the frequentist paradigm that whe consider only one model.</p>
<p>Table @ref(tab:RU-486prior) specifies the prior probabilities that we want to assign to our assumption. There is no unique correct prior, but any prior probability should reflect our beliefs prior to the experiement. The prior probabilities should incorporate the information from all relevant research before we perform the current experiement.</p>
<table>
<caption>(#tab:RU-486prior)Prior, likelihood, and posterior probabilities for each of the 9 models</caption>
<tbody>
<tr class="odd">
<td align="left">Model (<span class="math inline">\(p\)</span>)</td>
<td align="right">0.1000</td>
<td align="right">0.2000</td>
<td align="right">0.3000</td>
<td align="right">0.4000</td>
<td align="right">0.5000</td>
<td align="right">6e-01</td>
<td align="right">0.70</td>
<td align="right">0.80</td>
<td align="right">0.90</td>
</tr>
<tr class="even">
<td align="left">Prior <span class="math inline">\(P(model)\)</span></td>
<td align="right">0.0600</td>
<td align="right">0.0600</td>
<td align="right">0.0600</td>
<td align="right">0.0600</td>
<td align="right">0.5200</td>
<td align="right">6e-02</td>
<td align="right">0.06</td>
<td align="right">0.06</td>
<td align="right">0.06</td>
</tr>
<tr class="odd">
<td align="left">Likelihood <span class="math inline">\(P(data|model)\)</span></td>
<td align="right">0.0898</td>
<td align="right">0.2182</td>
<td align="right">0.1304</td>
<td align="right">0.0350</td>
<td align="right">0.0046</td>
<td align="right">3e-04</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(P(data|model)\)</span> x <span class="math inline">\(P(model)\)</span></td>
<td align="right">0.0054</td>
<td align="right">0.0131</td>
<td align="right">0.0078</td>
<td align="right">0.0021</td>
<td align="right">0.0024</td>
<td align="right">0e+00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">Posterior <span class="math inline">\(P(model|data)\)</span></td>
<td align="right">0.1748</td>
<td align="right">0.4248</td>
<td align="right">0.2539</td>
<td align="right">0.0681</td>
<td align="right">0.0780</td>
<td align="right">5e-04</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
</tbody>
</table>
<p>This prior incorporates two beliefs: the probability of <span class="math inline">\(p = 0.5\)</span> is highest, and the benefit of the treatment is symmetric. The second belief means that the treatment is equally likely to be better or worse than the standard treatment. Now it is natural to ask how I came up with this prior, and the specification will be discussed in detail later in the course.</p>
<p>Next, let’s calculate the likelihood – the probability of observed data for each model considered. In mathematical terms, we have</p>
<p><span class="math display">\[ P(\text{data}|\text{model}) = P(k = 4 | n = 20, p)\]</span></p>
<p>The likelihood can be computed as a binomial with 4 successes and 20 trials with <span class="math inline">\(p\)</span> is equal to the assumed value in each model. The values are listed in Table @ref(tab:RU-486prior).</p>
<p>After setting up the prior and computing the likelihood, we are ready to calculate the posterior using the Bayes’ rule, that is,</p>
<p><span class="math display">\[P(\text{model}|\text{data}) = \frac{P(\text{model})P(\text{data}|\text{model})}{P(\text{data})}\]</span></p>
<p>The posterior probability values are also listed in Table @ref(tab:RU-486prior), and the highest probability occurs at <span class="math inline">\(p=0.2\)</span>, which is 42.48%. Note that the priors and posteriors across all models both sum to 1.</p>
<p>In decision making, we choose the model with the highest posterior probability, which is <span class="math inline">\(p=0.2\)</span>. In comparison, the highest prior probability is at <span class="math inline">\(p=0.5\)</span> with 52%, and the posterior probability of <span class="math inline">\(p=0.5\)</span> drops to 7.8%. This demonstrates how we update our beliefs based on observed data. Note that the calculation of posterior, likelihood, and prior is unrelated to the frequentist concept (data “at least as extreme as observed”).</p>
<p>Here are the histograms of the prior, the likelihood, and the posterior probabilities:</p>
<div class="figure">
<img src="01-basics-02-inf-for-prop_files/figure-html/RU-486plot-1.png" alt="Original: sample size $n=20$ and number of successes $k=4$" width="960" />
<p class="caption">
(#fig:RU-486plot)Original: sample size <span class="math inline">\(n=20\)</span> and number of successes <span class="math inline">\(k=4\)</span>
</p>
</div>
<p>We started with the high prior at <span class="math inline">\(p=0.5\)</span>, but the data likelihood peaks at <span class="math inline">\(p=0.2\)</span>. And we updated our prior based on observed data to find the posterior. The Bayesian paradigm, unlike the frequentist approach, allows us to make direct probability statements about our models. For example, we can calculate the probability that RU-486, the treatment, is more effective than the control as the sum of the posteriors of the models where <span class="math inline">\(p&lt;0.5\)</span>. Adding up the relevant posterior probabilities in Table @ref(tab:RU-486prior), we get the chance that the treatment is more effective than the control is 92.16%.</p>
</div>
<div id="effect-of-sample-size-on-the-posterior" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Effect of Sample Size on the Posterior</h3>
<p>The RU-486 example is summarized in Figure @ref(fig:RU-486plot), and let’s look at what the posterior distribution would look like if we had more data.</p>
<div class="figure">
<img src="01-basics-02-inf-for-prop_files/figure-html/RU-486plotX2-1.png" alt="More data: sample size $n=40$ and number of successes $k=8$" width="960" />
<p class="caption">
(#fig:RU-486plotX2)More data: sample size <span class="math inline">\(n=40\)</span> and number of successes <span class="math inline">\(k=8\)</span>
</p>
</div>
<p>Suppose our sample size was 40 instead of 20, and the number of successes was 8 instead of 4. Note that the ratio between the sample size and the number of successes is still 20%. We will start with the same prior distribution. Then calculate the likelihood of the data which is also centered at 0.20, but is less variable than the original likelihood we had with the smaller sample size. And finally put these two together to obtain the posterior distribution. The posterior also has a peak at p is equal to 0.20, but the peak is taller, as shown in Figure @ref(fig:RU-486plotX2). In other words, there is more mass on that model, and less on the others.</p>
<div class="figure">
<img src="01-basics-02-inf-for-prop_files/figure-html/RU-486plotX10-1.png" alt="More data: sample size $n=200$ and number of successes $k=40$" width="960" />
<p class="caption">
(#fig:RU-486plotX10)More data: sample size <span class="math inline">\(n=200\)</span> and number of successes <span class="math inline">\(k=40\)</span>
</p>
</div>
<p>To illustrate the effect of the sample size even further, we’re going to keep increasing our sample size, but still maintain the the 20% ratio between the sample size and the number of successes. So let’s consider a sample with 200 observations and 40 successes. Once again, we’re going to use the same prior and the likelihood is again centered at 20% and almost all of the probability mass in the posterior is at p is equal to 0.20. The other models do not have zero probability mass, but they’re posterior probabilities are very close to zero.</p>
<p>Figure @ref(fig:RU-486plotX10) demonstrates that <strong>as more data are collected, the likelihood ends up dominating the prior</strong>. This is why, while a good prior helps, a bad prior can be overcome with a large sample. However, it’s important to note that this will only work as long as we don’t place a zero probability mass on any of the models in the prior.</p>
<!--chapter:end:01-basics-02-inf-for-prop.Rmd-->
</div>
</div>
<div id="frequentist-vs.bayesian-inference" class="section level2">
<h2><span class="header-section-number">1.3</span> Frequentist vs. Bayesian Inference</h2>
<div id="frequentist-vs.bayesian-inference-1" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Frequentist vs. Bayesian Inference</h3>
<p>In this section, we will solve a simple inference problem using both frequentist and Bayesian approaches. Then we will compare our results based on decisions based on the two methods, to see whether we get the same answer or not. If we do not, we will discuss why that happens.</p>

<div class="example">
<p><span id="ex:MM" class="example"><strong>(#ex:MM)</strong></span>We have a population of M&amp;M’s, and in this population the percentage of yellow M&amp;M’s is either 10% or 20%. You’ve been hired as a statistical consultant to decide whether the true percentage of yellow M&amp;M’s is 10% or 20%.</p>
<p>Payoffs/losses: You are being asked to make a decision, and there are associated payoff/losses that you should consider. If you make the correct decision, your boss gives you a bonus. On the other hand, if you make the wrong decision, you lose your job.</p>
<p>Data: You can “buy” a random sample from the population – You pay $200 for each M&amp;M, and you must buy in $1,000 increments (5 M&amp;Ms at a time). You have a total of $4,000 to spend, i.e., you may buy 5, 10, 15, or 20 M&amp;Ms.</p>
Remark: Remember that the cost of making a wrong decision is high, so you want to be fairly confident of your decision. At the same time, though, data collection is also costly, so you don’t want to pay for a sample larger than you need. If you believe that you could actually make a correct decision using a smaller sample size, you might choose to do so and save money and resources.
</div>
<p></p>
<p>Let’s start with the frequentist inference.</p>
<ul>
<li><p>Hypothesis: <span class="math inline">\(H_0\)</span> is 10% yellow M&amp;Ms, and <span class="math inline">\(H_A\)</span> is &gt;10% yellow M&amp;Ms.</p></li>
<li><p>Significance level: <span class="math inline">\(\alpha = 0.05\)</span>.</p></li>
<li><p>Sample: red, green, <strong>yellow</strong>, blue, orange</p></li>
<li><p>Observed data: <span class="math inline">\(k=1, n=5\)</span></p></li>
<li><p>P-value: <span class="math inline">\(P(k \geq 1 | n=5, p=0.10) = 1 - P(k=0 | n=5, p=0.10) = 1 - 0.90^5 \approx 0.41\)</span></p></li>
</ul>
<p>Note that the p-value is the probability of observed or more extreme outcome given that the null hypothesis is true.</p>
<p>Therefore, we fail to reject <span class="math inline">\(H_0\)</span> and conclude that the data do not provide convincing evidence that the proportion of yellow M&amp;M’s is greater than 10%. This means that if we had to pick between 10% and 20% for the proportion of M&amp;M’s, even though this hypothesis testing procedure does not actually confirm the null hypothesis, we would likely stick with 10% since we couldn’t find evidence that the proportion of yellow M&amp;M’s is greater than 10%.</p>
<p>The Bayesian inference works differently as below.</p>
<ul>
<li><p>Hypotheses: <span class="math inline">\(H_1\)</span> is 10% yellow M&amp;Ms, and <span class="math inline">\(H_2\)</span> is 20% yellow M&amp;Ms.</p></li>
<li><p>Prior: <span class="math inline">\(P(H_1) = P(H_2) = 0.5\)</span></p></li>
<li><p>Sample: red, green, <strong>yellow</strong>, blue, orange</p></li>
<li><p>Observed data: <span class="math inline">\(k=1, n=5\)</span></p></li>
<li><p>Likelihood:</p></li>
</ul>
<p><span class="math display">\[\begin{aligned}
P(k=1 | H_1) &amp;= \left( \begin{array}{c} 5 \\ 1 \end{array} \right) \times 0.10 \times 0.90^4 \approx 0.33 \\
P(k=1 | H_2) &amp;= \left( \begin{array}{c} 5 \\ 1 \end{array} \right) \times 0.20 \times 0.80^4 \approx 0.41
\end{aligned}\]</span></p>
<ul>
<li>Posterior</li>
</ul>
<p><span class="math display">\[\begin{aligned}
P(H_1 | k=1) &amp;= \frac{P(H_1)P(k=1 | H_1)}{P(k=1)} = \frac{0.5 \times 0.33}{0.5 \times 0.33 + 0.5 \times 0.41} \approx 0.45 \\
P(H_2 | k=1) &amp;= 1 - 0.45 = 0.55
\end{aligned}\]</span></p>
<p>The posterior probabilities of whether <span class="math inline">\(H_1\)</span> or <span class="math inline">\(H_2\)</span> is correct are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with a strong confidence, given the observed data. However, <span class="math inline">\(H_2\)</span> has a higher posterior probability than <span class="math inline">\(H_1\)</span>, so if we had to make a decision at this point, we should pick <span class="math inline">\(H_2\)</span>, i.e., the proportion of yellow M&amp;Ms is 20%. Note that this decision contradicts with the decision based on the frequentist approach.</p>
<p>Table @ref(tab:freq-vs-bayes) summarizes what the results would look like if we had chosen larger sample sizes. Under each of these scenarios, the frequentist method yields a higher p-value than our significance level, so we would fail to reject the null hypothesis with any of these samples. On the other hand, the Bayesian method always yields a higher posterior for the second model where <span class="math inline">\(p\)</span> is equal to 0.20. So the decisions that we would make are contradictory to each other.</p>
<table>
<caption>(#tab:freq-vs-bayes)Frequentist and Bayesian probabilities for larger sample sizes</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Frequentist</th>
<th align="left">Bayesian H_1</th>
<th align="left">Bayesian H_2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Observed Data</td>
<td align="left">P(k or more | 10% yellow)</td>
<td align="left">P(10% yellow | n, k)</td>
<td align="left">P(20% yellow | n, k)</td>
</tr>
<tr class="even">
<td>n = 5, k = 1</td>
<td align="left">0.41</td>
<td align="left">0.45</td>
<td align="left">0.55</td>
</tr>
<tr class="odd">
<td>n = 10, k = 2</td>
<td align="left">0.26</td>
<td align="left">0.39</td>
<td align="left">0.61</td>
</tr>
<tr class="even">
<td>n = 15, k = 3</td>
<td align="left">0.18</td>
<td align="left">0.34</td>
<td align="left">0.66</td>
</tr>
<tr class="odd">
<td>n = 20, k = 4</td>
<td align="left">0.13</td>
<td align="left">0.29</td>
<td align="left">0.71</td>
</tr>
</tbody>
</table>
<p>However, if we had set up our framework differently in the frequentist method and set our null hypothesis to be <span class="math inline">\(p = 0.20\)</span> and our alternative to be <span class="math inline">\(p &lt; 0.20\)</span>, we would obtain different results. This shows that <strong>the frequentist method is highly sensitive to the null hypothesis</strong>, while in the Bayesian method, our results would be the same regardless of which order we evaluate our models.</p>
<!--chapter:end:01-basics-03-freq-vs-bayes.Rmd-->
</div>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">1.4</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p><strong>Conditioning on dating site usage.</strong> Recall Table @ref(tab:2015gallupDating). What is the probability that an online dating site user from this sample is 18-29 years old?</p></li>
<li><p><strong>Probability of no HIV.</strong> Consider the ELISA test from Section @ref(diagnostic-testing). What is the probability that someone has no HIV if that person has a negative ELISA result? How does this compare to the probability of having no HIV before any test was done?</p></li>
<li><p><strong>Probability of no HIV after contradictive tests.</strong> Consider the ELISA test from Section @ref(diagnostic-testing). What is the probability that someone has no HIV if that person first tests positive on the ELISA and secondly test negative? Assume that the tests are independent from each other.</p></li>
</ol>
<!--chapter:end:01-basics-04-exercises.Rmd-->
</div>
</div>
<div id="bayesian-inference" class="section level1">
<h1><span class="header-section-number">2</span> Bayesian Inference</h1>
<p>This chapter is focused on the continuous version of Bayes’ rule and how to use it in a conjugate family. The RU-486 example will allow us to discuss Bayesian modeling in a concrete way. It also leads naturally to a Bayesian analysis without conjugacy. For the non-conjugate case, there’s usually no simple mathematical expression, and one must resort to computation. Finally, we discuss credible intervals, i.e., the Bayesian analog of frequentist confidence intervals, and Bayesian estimation and prediction.</p>
<p>It is assumed that the readers have mastered the concept of conditional probability and the Bayes’ rule for discrete random variables. Calculus is not required for this chapter; however, for those who do, we shall briefly look at an integral.</p>
<!--chapter:end:02-inference-00-intro.Rmd-->
<div id="continuous-variables-and-eliciting-probability-distributions" class="section level2">
<h2><span class="header-section-number">2.1</span> Continuous Variables and Eliciting Probability Distributions</h2>
<div id="from-the-discrete-to-the-continuous" class="section level3">
<h3><span class="header-section-number">2.1.1</span> From the Discrete to the Continuous</h3>
<p>This section leads the reader from the discrete random variable to continuous random variables. Let’s start with the binomial random variable such as the number of heads in ten coin tosses, can only take a discrete number of values – 0, 1, 2, up to 10.</p>
<p>When the probability of a coin landing heads is <span class="math inline">\(p\)</span>, the chance of getting <span class="math inline">\(k\)</span> heads in <span class="math inline">\(n\)</span> tosses is</p>
<p><span class="math display">\[P(X = k) = \left( \begin{array}{c} n \\ k \end{array} \right) p^k (1-p)^{n-k}\]</span>.</p>
<p>This formula is called the <strong>probability mass function</strong> (pmf) for the binomial.</p>
<p>The probability mass function can be visualized as a histogram in Figure @ref(fig:histogram). The area under the histogram is one, and the area of each bar is the probability of seeing a binomial random variable, whose value is equal to the x-value at the center of the bars base.</p>
<div class="figure" style="text-align: center">
<img src="02-inference-01-continuous_files/figure-html/histogram-1.png" alt="Histogram of binomial random variable" width="288" />
<p class="caption">
(#fig:histogram)Histogram of binomial random variable
</p>
</div>
<p>In contrast, the normal distribution, a.k.a. Gaussian distribution or the bell-shaped curve, can take any numerical value in <span class="math inline">\((-\infty,+\infty)\)</span>. A random variable generated from a normal distribution because it can take a continuum of values.</p>
<p>In general, if the set of possible values a random variable can take are separated points, it is a discrete random variable. But if it can take any value in some (possibly infinite) interval, then it is a continuous random variable.</p>
<p>When the random variable is <strong>discrete</strong>, it has a <strong>probability mass function</strong> or pmf. That pmf tells us the probability that the random variable takes each of the possible values. But when the random variable is continuous, it has probability zero of taking any single value. (Hence probability zero does not equal to impossible, an event of probabilty zero can still happen.)</p>
<p>We can only talk about the probability of a continuous random variable lined within some interval. For example, suppose that heights are approximately normally distributed. The probability of finding someone who is exactly 6 feet tall at 0.0000 inches tall for an infinite number of 0s after the decimal point is 0. But we can easily calculate the probability of finding someone who is between 5’11&quot; inches tall and 6’1&quot; inches tall.</p>
<p>A <strong>continuous</strong> random variable has a <strong>probability density function</strong> or pdf, instead of probability mass functions. The probability of finding someone whose height lies between 5’11&quot; and 6’1&quot; is the area under the pdf curve for height between those two values.</p>
<p>NEED TO GET THE PLOTS HERE</p>
<p>For example, a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> (i.e., variance <span class="math inline">\(\sigma^2\)</span>) is defined as</p>
<p><span class="math display">\[f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp[-\frac{1}{2\sigma^2}(x-\mu)^2],\]</span></p>
<p>where <span class="math inline">\(x\)</span> is any value the random variable <span class="math inline">\(X\)</span> can take. This is denoted as <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>, where <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> are the parameters of the normal distribution.</p>
<p>Recall that a probability mass function assigns the probability that a random variable takes a specific value for the discrete set of possible values. The sum of those probabilities over all possible values must equal one.</p>
<p>Similarly, a probability density function is any <span class="math inline">\(f(x)\)</span> that is non-negative and has area one underneath its curve. The pdf can be regarded as the limit of histograms made from its sample data. As the sample size becomes infinitely large, the bin width of the histogram shrinks to zero.</p>
<p>There are infinite number of pmf’s and an infinite number of pdf’s. Some distributions are so important that they have been given names:</p>
<ul>
<li><p>Continuous: normal, uniform, beta, gamma</p></li>
<li><p>Discrete: binomial, Poisson</p></li>
</ul>
<p>Here is a summary of the key ideas in this section:</p>
<ol style="list-style-type: decimal">
<li><p>Continuous random variables exist and they can take any value within some possibly infinite range.</p></li>
<li><p>The probability that a continuous random variable takes a specific value is zero.</p></li>
<li><p>Probabilities from a continuous random variable are determined by the density function with this non-negative and the area beneath it is one.</p></li>
<li><p>We can find the probability that a random variable lies between two values (<span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>) as the area under the density function that lies between them.</p></li>
</ol>
</div>
<div id="elicitation" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Elicitation</h3>
<p>Next, we introduce the concept of prior elicitation in base and statistics. Often, one has a belief about the distribution of one’s data. You may think that your data come from a binomial distribution and in that case you typically know the <span class="math inline">\(n\)</span>, the number of trials but you usually do not know <span class="math inline">\(p\)</span>, the probability of success. Or you may think that your data come from a normal distribution. But you do not know the mean <span class="math inline">\(\mu\)</span> or the standard deviation <span class="math inline">\(\sigma\)</span> of the normal. Beside to knowing the distribution of one’s data, you may also have beliefs about the unknown <span class="math inline">\(p\)</span> in the binomial or the unknown mean <span class="math inline">\(\mu\)</span> in the normal.</p>
<p>Bayesians express their belief in terms of personal probabilities. These personal probabilities encapsulate everything a Bayesian knows or believes about the problem. But these beliefs must obey the laws of probability, and be consistent with everything else the Bayesian knows.</p>

<div class="example">
<span id="ex:unnamed-chunk-1" class="example"><strong>(#ex:unnamed-chunk-1)</strong></span>You cannot say that your probability of passing this course is 200%, no matter how confident you are. A probability value must be between zero and one. (If you still think you have a probability of 200% to pass the course, you are definitely not going to pass it.)
</div>
<p></p>

<div class="example">
<span id="ex:unnamed-chunk-2" class="example"><strong>(#ex:unnamed-chunk-2)</strong></span>You may know nothing at all about the value of <span class="math inline">\(p\)</span> that generated some binomial data. In which case any value between zero and one is equally likely, you may want to make an inference on the proportion of people who would buy a new band of toothpaste. If you have industry experience, you may have a strong belief about the value of <span class="math inline">\(p\)</span>, but if you are new to the industry you would do nothing about <span class="math inline">\(p\)</span>. In any value between zero and one seems equally like a deal. This major personal probability is the uniform distribution whose probably density function is flat, denoted as <span class="math inline">\(\text{Unif}(0,1)\)</span>.
</div>
<p></p>

<div class="example">
<span id="ex:unnamed-chunk-3" class="example"><strong>(#ex:unnamed-chunk-3)</strong></span>If you were tossing a coin, most people believed that the probability of heads is pretty close to half. They know that some coin are loaded and they know that some coins may have two heads or two tails. And they probably also know that coins are not perfectly balanced. Nonetheless, before they start to collect data by tossing the coin and counting the number of heads their belief is that values of <span class="math inline">\(p\)</span> near 0.5 are very likely, where’s values of <span class="math inline">\(p\)</span> near 0 or 1 are very unlikely.
</div>
<p></p>

<div class="example">
<span id="ex:unnamed-chunk-4" class="example"><strong>(#ex:unnamed-chunk-4)</strong></span>In real life, here are two ways to elicit a probability that you cousin will get married. A frequentist might go to the U.S. Census records and determine what proportion of people get married (or, better, what proportion of people of your cousin’s ethnicity, education level, religion, and age cohort are married). In contrast, a Bayesian might think “My cousin is brilliant, attractive, and fun. The probability that my cousin gets married is really high – probably around 0.97.”
</div>
<p></p>
<p>So a base angle sits to express their belief about the value of <span class="math inline">\(p\)</span> through a probability distribution, and a very flexible family of distributions for this purpose is the <strong>beta family</strong>. A member of the beta family is specified by two parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>; we denote this as <span class="math inline">\(p \sim \text{beta}(\alpha, \beta)\)</span>. The probability density function is</p>
<span class="math display">\[\begin{equation}
f(p) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} p^{\alpha-1} (1-p)^{\beta-1},
(\#eq:beta)
\end{equation}\]</span>
<p>where <span class="math inline">\(0 \leq p \leq 1, \alpha&gt;0, \beta&gt;0\)</span>, and <span class="math inline">\(\Gamma\)</span> is a factorial:</p>
<p><span class="math display">\[\Gamma(n) = (n-1)! = (n-1) \times (n-2) \times \cdots \times 1\]</span></p>
<p>When <span class="math inline">\(\alpha=\beta=1\)</span>, the beta distribution becomes a uniform distribution, i.e. the probabilty density function is a flat line. In other words, the uniform distribution is a special case of the beta family.</p>
<p>The expected value of <span class="math inline">\(p\)</span> is <span class="math inline">\(\frac{\alpha}{\alpha+\beta}\)</span>, so <span class="math inline">\(\alpha\)</span> can be regarded as the prior number of successes, and <span class="math inline">\(\beta\)</span> the prior number of failures. When <span class="math inline">\(\alpha=\beta\)</span>, then one gets a symmetrical pdf around 0.5. For large but equal values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, the area under the beta probability density near 0.5 is very large. Figure @ref(fig:beta) compares the beta distribution with different parameter values.</p>
<div class="figure">
<img src="02-inference-01-continuous_files/figure-html/beta-1.png" alt="Beta family" width="672" />
<p class="caption">
(#fig:beta)Beta family
</p>
</div>
<p>These kinds of priors are probably appropriate if you want to infer the probability of getting heads in a coin toss. The beta family also includes skewed densities, which is appropriate if you think that <span class="math inline">\(p\)</span> the probability of success in ths binomial trial is close to zero or one.</p>
<p>Bayes’ rule is a machine to turn one’s prior beliefs into posterior beliefs. With binomial data you start with whatever beliefs you may have about <span class="math inline">\(p\)</span>, then you observe data in the form of the number of head, say 20 tosses of a coin with 15 heads.</p>
<p>Next, Bayes’ rule tells you how the data changes your opinion about <span class="math inline">\(p\)</span>. The same principle applies to all other inferences. You start with your prior probability distribution over some parameter, then you use data to update that distribution to become the posterior distribution that expresses your new belief.</p>
<p>These rules ensure that the change in distributions from prior to posterior is the uniquely rational solution. So, as long as you begin with the prior distribution that reflects your true opinion, you can hardly go wrong.</p>
<p>However, expressing that prior can be difficult. There are proofs and methods whereby a rational and coherent thinker can self-illicit their true prior distribution, but these are impractical and people are rarely rational and coherent.</p>
<p>The good news is that with the few simple conditions no matter what part distribution you choose. If enough data are observed, you will converge to an accurate posterior distribution. So, two bayesians, say the reference Thomas Bayes and the agnostic Ajay Good can start with different priors but, observe the same data. As the amount of data increases, they will converge to the same posterior distribution.</p>
<p>Here is a summary of the key ideas in this section:</p>
<ol style="list-style-type: decimal">
<li><p>Bayesians express their uncertainty through probability distributions.</p></li>
<li><p>One can think about the situation and self-elicit a probability distribution that approximately reflects his/her personal probability.</p></li>
<li><p>One’s personal probability should change according Bayes’ rule, as new data are observed.</p></li>
<li><p>The beta family of distribution can describe a wide range of prior beliefs.</p></li>
</ol>
</div>
<div id="conjugacy" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Conjugacy</h3>
<p>Next, let’s introduce the concept of conjugacy in Bayesian statistics.</p>
<p>Suppose we have the prior beliefs about the data as below:</p>
<ul>
<li><p>Binomial distribution <span class="math inline">\(\text{Bin}(n,p)\)</span> with <span class="math inline">\(n\)</span> known and <span class="math inline">\(p\)</span> unknown</p></li>
<li><p>Prior belief about <span class="math inline">\(p\)</span> is <span class="math inline">\(\text{beta}(\alpha,\beta)\)</span></p></li>
</ul>
<p>Then we observe <span class="math inline">\(x\)</span> success in <span class="math inline">\(n\)</span> trials, and it turns out the Bayes’ rule implies that our new belief about the probability density of <span class="math inline">\(p\)</span> is also the beta distribution, but with different parameters. In mathematical terms,</p>
<span class="math display">\[\begin{equation}
p|x \sim \text{beta}(\alpha+x, \beta+n-x).
(\#eq:beta-binomial)
\end{equation}\]</span>
<p>This is an example of conjugacy. Conjugacy occurs when the <strong>posterior distribution</strong> is in the <strong>same family</strong> of probability density functions as the prior belief, but with <strong>new parameter values</strong>, which have been updated to reflect what we have learned from the data.</p>
<p>Why are the beta binomial families conjugate? Here is a mathematical explanation.</p>
<p>Recall the discrete form of the Bayes’ rule:</p>
<p><span class="math display">\[P(A_i|B) = \frac{P(B|A_i)P(A_i)}{\sum^n_{j=1}P(B|A_j)P(A_j)}\]</span></p>
<p>However, this formula does not apply to continuous random variables, such as the <span class="math inline">\(p\)</span> which follows a beta distribution, because the denominator sums over all possible values (must be finitely many) of the random variable.</p>
<p>But the good news is that the <span class="math inline">\(p\)</span> has a finite range – it can tak any value <strong>only</strong> between 0 and 1. Hence we can perform integration, which is a generalization of the summation. The Bayes’ rule can also be written in continuous form as:</p>
<p><span class="math display">\[\pi^*(p|x) = \frac{P(x|p)\pi(p)}{\int^1_0 P(x|p)\pi(p) dp}.\]</span></p>
<p>This is analogus to the discrete form, since the integral in the denominator will also be equal to some constant, just like a summation. This constant ensures that the total area under the curve, i.e. the posterior density function, equals 1.</p>
<p>Note that in the numerator, the first term, <span class="math inline">\(P(x|p)\)</span>, is the data likelihood – the probability of observing the data given a specific value of <span class="math inline">\(p\)</span>. The second term, <span class="math inline">\(\pi(p)\)</span>, is the probability density function that reflects the prior belief about <span class="math inline">\(p\)</span>.</p>
<p>In the beta-binomial case, we have <span class="math inline">\(P(x|p)=\text{Bin}(n,p)\)</span> and <span class="math inline">\(\pi(p)=\text{beta}(\alpha,\beta)\)</span>.</p>
<p>Plugging in these distributions, we get</p>
<p><span class="math display">\[\begin{aligned}
\pi^*(p|x) &amp;= \frac{1}{\text{some number}} \times P(x|p)\pi(p) \\
&amp;= \frac{1}{\text{some number}} [\left( \begin{array}{c} n \\ x \end{array} \right) p^x (1-p)^{n-x}] [\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} p^{\alpha-1} (1-p)^{\beta-1}] \\
&amp;= \frac{\Gamma(\alpha+\beta+n)}{\Gamma(\alpha+x)\Gamma(\beta+n-x)} \times p^{\alpha+x-1} (1-p)^{\beta+n-x-1}
\end{aligned}\]</span></p>
<p>Let <span class="math inline">\(\alpha^* = \alpha + x\)</span> and <span class="math inline">\(\beta^* = \beta+n-x\)</span>, and we get</p>
<p><span class="math display">\[\pi^*(p|x) = \text{beta}(\alpha^*,\beta^*) = \text{beta}(\alpha+x, \beta+n-x),\]</span></p>
<p>same as the posterior formula in Equation @ref(eq:beta-binomial).</p>
<p>We can recognize the posterior distribution from the numerator <span class="math inline">\(p^{\alpha+x-1}\)</span> and <span class="math inline">\((1-p)^{\beta+n-x-1}\)</span>. Everything else are just constants, and they must take the unique value, which is needed to ensure that the area under the curve between 0 and 1 equals 1. So they have to take the values of the beta, which has parameters <span class="math inline">\(\alpha+x\)</span> and <span class="math inline">\(\beta+n-x\)</span>.</p>
<p>This is a cute trick. We can find the answer without doing the integral simply by looking at form of the numerator.</p>
<p>Without conjugacy, one has to do the integral. Often, the integral is impossible to evaluate. That obstacle is the primary reason that most statistical theory in the 20th century was not Bayesian. The situation didn’t change until modern computing allowed researchers to compute integrals numerically.</p>
<p>In summary, some pairs of distributions are conjugate. If your prior is in one and your data comes from the other, then your posterior is in the same family as the prior, but with new parameters. We explored this in the context of the beta-binomial conjugate families. And we saw that conjugacy meant that we could apply the continuous version of Bayes’ rule without having to do any integration.</p>
<!--chapter:end:02-inference-01-continuous.Rmd-->
</div>
</div>
<div id="three-conjugate-families" class="section level2">
<h2><span class="header-section-number">2.2</span> Three Conjugate Families</h2>
<p>Missing: Gamma plot in 2.2.2</p>
<div id="inference-on-a-binomial-proportion" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Inference on a Binomial Proportion</h3>

<div class="example">
<p><span id="ex:RU-486more" class="example"><strong>(#ex:RU-486more)</strong></span>Recall Example @ref(ex:RU-486), a simplified version of a real clinical trial taken in Scotland. It concerned RU-486, a morning after pill that was being studied to determine whether it was effective at preventing unwanted pregnancies. It had 800 women, each of whom had intercourse no more than 72 hours before reporting to a family planning clinic to seek contraception.</p>
Half of these women were randomly assigned to the standard contraceptive, a large dose of estrogen and progesterone. And half of the women were assigned RU-486. Among the RU-486 group, there were no pregnancies. Among those receiving the standard therapy, four became pregnant.
</div>
<p></p>
<p>Statistically, one can model these data as coming from a binomial distribution. Imagine a coin with two sides. One side is labeled standard therapy and the other is labeled RU-486. The coin was tossed four times, and each time it landed with the standard therapy side face up.</p>
<p>A frequentist would analyze the problem as below:</p>
<ul>
<li><p>The parameter <span class="math inline">\(p\)</span> is the probability of a preganancy comes from the standard treatment.</p></li>
<li><p><span class="math inline">\(H_0: p \geq 0.5\)</span> and <span class="math inline">\(H_A: p &lt; 0.5\)</span></p></li>
<li><p>The p-value is <span class="math inline">\(0.5^4 = 0.0625 &gt; 0.05\)</span></p></li>
</ul>
<p>Therefore, the frequentist fails to reject the null hypothesis, and will not conclude that RU-486 is superior to standard therapy.</p>
<p>Remark: The significance probability, or p-value, is the chance of observing data that are as or more supportive of the alternative hypothesis than the data that were collected, when the null hypothesis is true.</p>
<p>Now suppose a Bayesian performed the analysis. She may set her beliefs about the drug and decide that she has no prior knowledge about the efficacy of RU-486 at all. This would be reasonable if, for example, it were the first clinical trial of the drug. In that case, she would be using the uniform distribution on the interval from 0 to 1, which corresponds to the <span class="math inline">\(\text{beta}(1,1)\)</span> density. In mathematical terms,</p>
<p><span class="math display">\[p \sim \text{Unif}(0,1) = \text{beta}(1,1).\]</span></p>
<p>From conjugacy, we know that since there were four failures for RU-486 and no successes, that her posterior probability of an RU-486 child is</p>
<p><span class="math display">\[p|x \sim \text{beta}(1+0,1+4) = \text{beta}(1,5).\]</span></p>
<p>This is a beta that has much more area near <span class="math inline">\(p\)</span> equal to 0. The mean of <span class="math inline">\(\text{beta}(\alpha,\beta)\)</span> is <span class="math inline">\(\frac{\alpha}{\alpha+\beta}\)</span>. So this Bayesian now believes that the unknown <span class="math inline">\(p\)</span>, the probability of an RU-468 child, is about 1 over 6.</p>
<p>The standard deviation of a beta distribution with parameters in alpha and beta also has a closed form:</p>
<p><span class="math display">\[p \sim \text{beta}(\alpha,\beta) \Rightarrow \text{Standard deviation} = \sqrt{\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}}\]</span></p>
<p>Before she saw the data, the Bayesian’s uncertainty expressed by her standard deviation was 0.71. After seeing the data, it was much reduced – her posterior standard deviation is just 0.13.</p>
<p>We promised not to do much calculus, so I hope you will trust me to tell you that this Bayesian now believes that her posterior probability that <span class="math inline">\(p &lt; 0.5\)</span> is 0.96875. She thought there was a 50-50 chance that RU-486 is better. But now she thinks there’s about a 97% chance that RU-486 is better.</p>
<p>Suppose a fifth child were born, also to a mother who received standard chip therapy. Now the Bayesian’s prior is beta(1, 5) and the additional data point further updates her to a new posterior beta of 1 and 6. <strong>As data comes in, the Bayesian’s previous posterior becomes her new prior, so learning is self-consistent.</strong></p>
<p>This example has taught us several things:</p>
<ol style="list-style-type: decimal">
<li><p>We saw how to build a statistical model for an applied problem.</p></li>
<li><p>We could compare the frequentist and Bayesian approaches to inference and see large differences in the conclusions.</p></li>
<li><p>We saw how the data changed the Bayesian’s opinion with a new mean for p and less uncertainty.</p></li>
<li><p>We learned that Bayesian’s continually update as new data arrive. <strong>Yesterday’s posterior is today’s prior.</strong></p></li>
</ol>
</div>
<div id="the-gamma-poisson-conjugate-families" class="section level3">
<h3><span class="header-section-number">2.2.2</span> The Gamma-Poisson Conjugate Families</h3>
<p>A second important case is the gamma-Poisson conjugate families. In this case the data come from a Poisson distribution, and the prior and posterior are both gamma distributions.</p>
<p>The Poisson random variable can take any <strong>non-negative integer value</strong> all the way up to infinity. It is used in describing <strong>count data</strong>, where one counts the number of independent events that occur in a fixed amount of time, a fixed area, or a fixed volume.</p>
<p>Moreover, the Poisson distribution has been used to describe the number of phone calls one receives in an hour. Or, the number of pediatric cancer cases in the city, for example, to see if pollution has elevated the cancer rate above that of in previous years or for similar cities. It is also used in medical screening for diseases, such as HIV, where one can count the number of T-cells in the tissue sample.</p>
<p>The Poisson distribution has a single parameter <span class="math inline">\(\lambda\)</span>, and it is denoted as <span class="math inline">\(X \sim \text{Pois}(\lambda)\)</span> with <span class="math inline">\(\lambda&gt;0\)</span>. The probability mass function is</p>
<p><span class="math display">\[P(X=k) = \frac{\lambda^k}{k!} \exp^{-\lambda} \text{ for } k=0,1,\cdots,\]</span></p>
<p>where <span class="math inline">\(k! = k \times (k-1) \times \cdots \times 1\)</span>. This gives the probability of observing a random variable equal to <span class="math inline">\(k\)</span>.</p>
<p>Note that <span class="math inline">\(\lambda\)</span> is both the mean and the variance of the Poisson random variable. It is obvious that <span class="math inline">\(\lambda\)</span> must be greater than zero, because it represents the mean number of counts, and the variance should be greater than zero (except for constants, which have zero variance).</p>

<div class="example">
<p><span id="ex:Poisson" class="example"><strong>(#ex:Poisson)</strong></span>Famously, von Bortkiewicz used the Poisson distribution to study the number of Prussian cavalrymen who were kicked to death by a horse each year. This is count data over the course of a year, and the events are probably independent, so the Poisson model makes sense.</p>
<p>He had data on 15 cavalry units for the 20 years between 1875 and 1894, inclusive. The total number of cavalrymen who died by horse kick was 200.</p>
One can imagine that a Prussian general might want to estimate <span class="math inline">\(\lambda\)</span>. The average number per year, per unit. Perhaps in order to see whether some educational campaign about best practices for equine safety would make a difference.
</div>
<p></p>
<p>Suppose the Prussian general is a Bayesian. Introspective elicitation leads him to think that <span class="math inline">\(\lambda=0.75\)</span> and standard deviation 1.</p>
<p>Modern computing was unavailable at that time yet, so the general will need to express his prior as a member of a family conjugate to the Poisson. It turns out that this family consists of the gamma distributions. Gamma distributions describe continuous non-negative random variables. As we know, the value of lambda in the Poisson can take any non-negative value so this fits.</p>
<p>And, the gamma family is pretty flexible, one can see a wide range of gamma shapes.</p>
<p>NEED TO GET THE GAMMA PLOT HERE</p>
<p>The probability density function for the gamma is indexed by shape <span class="math inline">\(k\)</span> and scale <span class="math inline">\(\theta\)</span>, denoted as <span class="math inline">\(\text{Gamma}(k,\theta)\)</span> with <span class="math inline">\(k,\theta &gt; 0\)</span>. The mathematical form of the distribution is</p>
<p><span class="math display">\[f(x) = \dfrac{1}{\Gamma(k)\theta^k} x^{k-1} e^{-x/\theta},\]</span> where</p>
<p><span class="math display">\[\Gamma(z) = \int^{\infty}_0 x^{z-1} e^{-x} dx.\]</span></p>
<p><span class="math inline">\(\Gamma(z)\)</span>, the gamma function, is simply a constant that ensures the area under curve between 0 and 1 sums to 1, just like in the beta probability distribution case of Equation @ref(eq:beta). A special case is that <span class="math inline">\(\Gamma(n) = (n-1)!\)</span> when <span class="math inline">\(n\)</span> is a positive integer.</p>
<p>However, some books parameterize the gamma distribution in a slightly different way with shape <span class="math inline">\(\alpha = k\)</span> and rate (inverse scale) <span class="math inline">\(\beta=1/\theta\)</span>:</p>
<p><span class="math display">\[f(x) = \frac{\beta^{\alpha}}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}\]</span></p>
<p>In the supplementary material, we go with the <span class="math inline">\(k\)</span>-<span class="math inline">\(\theta\)</span> parameterization, but you should always check which parameterization is being used. For example, <span class="math inline">\(\mathsf{R}\)</span> uses the <span class="math inline">\(\alpha\)</span>-<span class="math inline">\(\beta\)</span> parameterization.</p>
<p>For our parameterization, the mean of <span class="math inline">\(\text{Gamma}(k,\theta)\)</span> is <span class="math inline">\(k\theta\)</span>, and the variance is <span class="math inline">\(k\theta^2\)</span>. We can get the general’s prior as below:</p>
<p><span class="math display">\[\begin{aligned}
\text{Mean} &amp;= k\theta = 0.75 \\
\text{Standard deviation} &amp;= \theta\sqrt{k} = 1
\end{aligned}\]</span></p>
<p>Hence <span class="math display">\[k = \frac{9}{16} \text{ and } \theta = \frac{4}{3}\]</span></p>
<p>For the gamma Poisson conjugate family, suppose we observed data <span class="math inline">\(x_1, x_2, \cdots, x_n\)</span> that follow a Poisson distribution.Then similar to the previous section, we would recognize the kernel of the gamma when using the gamma-Poisson family. The posterior <span class="math inline">\(\text{Gamma}(k^*, \theta^*)\)</span> has parameters</p>
<p><span class="math display">\[k^* = k + \sum^n_{i=1} x_i \text{ and } \theta^* = \frac{\theta}{(n\theta+1)}.\]</span></p>
<p>For this dataset, <span class="math inline">\(N = 15 \times 20 = 300\)</span> observations, and the number of casualities is 200. Therefore, the general now thinks that the average number of Prussian cavalry officers who die at the hoofs of their horses follows a gamma distribution with the parameters below:</p>
<p><span class="math display">\[\begin{aligned}
k^* &amp;= k + \sum^n_{i=1} x_i = \frac{9}{16} + 200 = 200.5625 \\
\theta^* = \frac{\theta}{(n\theta+1)} &amp;= \frac{4/3}{300\times(4/3)} = 0.0033
\end{aligned}\]</span></p>
<p>How the general has changed his mind is described in Table @ref(tab:before-after). After seeing the data, his uncertainty about lambda, expressed as a standard deviation, shrunk from 1 to 0.047.</p>
<table>
<caption>(#tab:before-after)Before and after seeing the data</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">lambda</th>
<th align="right">Standard Deviation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Before</td>
<td align="right">0.75</td>
<td align="right">1.000</td>
</tr>
<tr class="even">
<td>After</td>
<td align="right">0.67</td>
<td align="right">0.047</td>
</tr>
</tbody>
</table>
<p>In summary, we learned about the Poisson and gamma distributions; we also knew that the gamma-Poisson families are conjugate. Moreover, we learned the updating fomula, and applied it to a classical dataset.</p>
</div>
<div id="sec:normal-normal" class="section level3">
<h3><span class="header-section-number">2.2.3</span> The Normal-Normal Conjugate Families</h3>
<p>There are other conjugate families, and one is the normal-normal pair. If your data come from a normal distribution with known standard deviation <span class="math inline">\(\sigma\)</span> but unknown mean <span class="math inline">\(\mu\)</span>, and if your prior on the mean <span class="math inline">\(\mu\)</span>, has a normal distribution with self-elicited mean <span class="math inline">\(\nu\)</span> and self-elicited standard deviation <span class="math inline">\(\tau\)</span>, then your posterior density for the mean, after seeing a sample of size <span class="math inline">\(n\)</span> with sample mean <span class="math inline">\(\bar{x}\)</span>, is also normal. In mathematical notation, we have</p>
<p><span class="math display">\[\begin{aligned}
x|\mu &amp;\sim N(\mu,\sigma) \\
\mu &amp;\sim N(\nu, \tau)
\end{aligned}\]</span></p>
<p>As a practical matter, one often does not know sigma, the standard deviation of the normal from which the data come. In that case, you could use a more advanced conjugate family that we will describe in @ref(sec:normal-gamma). But there are cases in which it is reasonable to treat the <span class="math inline">\(\sigma\)</span> as known.</p>

<div class="example">
<p><span id="ex:chemist" class="example"><strong>(#ex:chemist)</strong></span>An analytical chemist whose balance produces measurements that are normally distributed with mean equal to the true mass of the sample and standard deviation that has been estimated by the manufacturer balance and confirmed against calibration standards provided by the National Institute of Standards and Technology.</p>
<p>Note that this normal-normal assumption made by the anayltical chemist is technically wrong, but still reasonable.</p>
<ol style="list-style-type: decimal">
<li><p>The normal family puts some probability on all possible values between <span class="math inline">\((-\infty,+\infty)\)</span>. But the mass on the balance can <strong>never</strong> be negative. However, the normal prior on the unknown mass is usually so concentrated on positive values that the normal distribution is still a good approximation.</p></li>
<li>Even if the chemist has repeatedly calibrated her balance with standards from the National Institute of Standards and Technology, she still will not know its standard deviation precisely. However, if she has done it often and well, it is probably a sufficiently good approximation to assume that the standard deviation is known.
</div>
<p></p></li>
</ol>
<p>For the normal-normal conjugate families, assume the prior on the unknown mean follows a normal distribution, i.e. <span class="math inline">\(\mu \sim N(\nu, \tau)\)</span>. We also assume that the data <span class="math inline">\(x_1,x_2,\cdots,x_n\)</span> are independent and come from a normal with standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<p>Then the posterior distribution of <span class="math inline">\(\mu\)</span> is also normal, with mean as a weighted average of the prior mean and the sample mean. We have</p>
<p><span class="math display">\[\mu|x_1,x_2,\cdots,x_n \sim N(\nu^*, \tau^*),\]</span></p>
<p>where</p>
<p><span class="math display">\[\nu^* = \frac{\nu\sigma^2 + n\bar{x}\tau^2}{\sigma^2 + n\tau^2} \text{ and } \tau^* = \sqrt{\frac{\sigma^2\tau^2}{\sigma^2 + n\tau^2}}.\]</span></p>
<p>Let’s continue from Example @ref(ex:chemist), and suppose she wants to measure the mass of a sample of ammonium nitrate.</p>
<p>Her balance has a known standard deviation of 0.2 milligrams. By looking at the sample, she thinks this mass is about 10 milligrams and based on her previous experience in estimating masses, her guess has the standard deviation of 2. So she decides that her prior for the mass of the sample is a normal distribution with mean, 10 milligrams, and standard deviation, 2 milligrams.</p>
<p>Now she collects five measurements on the sample and finds that the average of those is 10.5. By conjugacy of the normal-normal family, our posterior belief about the mass of the sample has the normal distribution.</p>
<p>The new mean of that posterior normal is found by plugging into the formula:</p>
<p><span class="math display">\[\begin{aligned}
\mu &amp;\sim N(\nu=10, \tau=2) \\
\nu^*  &amp;= \frac{\nu\sigma^2 + n\bar{x}\tau^2}{\sigma^2 + n\tau^2} = \frac{10\times(0.2)^2+5\times10.5\times2^2}{(0.2)^2+5\times2^2} = 10.499\\
\tau^* &amp;= \sqrt{\frac{\sigma^2\tau^2}{\sigma^2 + n\tau^2}} = \sqrt{(0.2)^2\times2^2}{(0.2)^2+5\times2^2} = 0.089.
\end{aligned}\]</span></p>
<p>Before seeing the data, the Bayesian analytical chemist thinks the ammonium nitrate has mass 10 mg and uncertainty (standard deviation) 2 mg. After seeing the data, she thinks the mass is 10.499 mg and standard deviation 0.089 mg. Her posterior mean has shifted quite a bit and her uncertainty has dropped by a lot. That’s exactly what an analytical chemist wants.</p>
<p>This is the last of the three examples of conjugate families. There are many more, but they do not suffice for every situation one might have.</p>
<p>We learned several things in this lecture. First, we learned the new pair of conjugate families and the relevant updating formula. Also, we worked a realistic example problem that can arise in practical situations.</p>
<!--chapter:end:02-inference-02-conjugate.Rmd-->
</div>
</div>
<div id="credible-intervals-and-predictive-inference" class="section level2">
<h2><span class="header-section-number">2.3</span> Credible Intervals and Predictive Inference</h2>
<p>Missing: JAGS plot for 2.3.1</p>
<div id="non-conjugate-priors" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Non-Conjugate Priors</h3>
<p>In many applications, a Bayesian may not be able to use a conjugate prior. Sometimes she may want to use a reference prior, which injects the minimum amount of personal belief into the analysis. But most often, a Bayesian will have a personal belief about the problem that cannot be expressed in terms of a convenient conjugate prior.</p>
<p>For example, we shall reconsider the RU-486 case from earlier in which four children were born to standard therapy mothers. But no children were born to RU-486 mothers. This time, the Bayesian believes that the probability p of an RU-486 baby is uniformly distributed between 0 and one-half, but has a point mass of 0.5 at one-half. That is, she believes there’s a 50% chance that there is no difference between standard therapy and RU-486. But if there is a difference, she thinks that RU-486 is better, but she is completely unsure about how much better it would be.</p>
<p>In mathematical notation, the probability density function of <span class="math inline">\(p\)</span> is</p>
<p><span class="math display">\[f_p(x) = \left\{ \begin{array}{ccc}
1 &amp; \text{for} &amp; 0 \leq x &lt; 0.5 \\
1 &amp; \text{for} &amp; x = 0.5 \\
0 &amp; \text{for} &amp; x &lt; 0 \text{ or } x &gt; 0.5
\end{array}\right.\]</span></p>
<p>We can check that the area under the density curve, plus the amount of the point mass, equals 1.</p>
<p>The cumulative distribution function of <span class="math inline">\(p\)</span> is</p>
<p><span class="math display">\[F_p(p \leq x) = \left\{ \begin{array}{ccc}
0 &amp; \text{for} &amp; x &lt; 0 \\
x &amp; \text{for} &amp; 0 \leq x &lt; 0.5  \\
1 &amp; \text{for} &amp; x \geq 0.5
\end{array}\right.\]</span></p>
<p>Why would this be a reasonable prior for an analyst to self-elicit? One reason is that in clinical trials, there’s actually quite a lot of preceding research on the efficacy of the drug. This research might be based on animal studies or knowledge of the chemical activity of the molecule. So the Bayesian might feel sure that there is no possibility that RU-486 is worse than the standard treatment. And her interest is on whether the therapies are equivalent and if not, how much better RU-486 is than the standard therapy.</p>
<p>As previously mentioned, there is no way to compute the posterior distribution for <span class="math inline">\(p\)</span> in a simple or even a complex mathematical form. And that is why Bayesian inference languished for so many decades until computational power enabled numerical solutions. But now we have such tools, and one of them is called <strong>JAGS (Just Another Gibbs Sampler)</strong>.</p>
<p>If we apply JAGS to the RU-486 data with this non-conjugate prior, we can find the posterior distribution. At a high level, this program is defining the binomial probability, that is the likelihood of seeing 0 RU-486 children, which is binomial. And then it defines the prior by using a few tricks to draw from either a uniform on the interval from 0 to one-half, or else draw from the point mass at one-half. Then it calls the JAGS model function, and draws 5,000 times from the posterior and creates a histogram of the results.</p>
<p>NEED TO GET THE JAGS PLOT HERE</p>
<p>That histogram is lightly smooth to generate the posterior density you see. There is still a point mass of probability at 0.5, but now it has less weight than before. Also, note how the data have changed the posterior away from the prior. The analyst sees a lot of probability under the curve near 0.2, but responds to the fact that no children were born to RU-486 mothers.</p>
<p>This section is mostly a look-ahead to future material. We have seen that a Bayesian might reasonably employ a non-conjugate prior in a practical application. But then she will need to employ some kind of numerical computation to approximate the posterior distribution. Additionally, we have used a computational tool, JAGS, to approximate the posterior for <span class="math inline">\(p\)</span>, and identified its three important elements, the probability of the data given <span class="math inline">\(p\)</span>, that is the likelihood, and the prior, and the call to the Gibbs sampler.</p>
</div>
<div id="credible-intervals" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Credible Intervals</h3>
<p>In this section, we introduce credible intervals, the Bayesian alternative to confidence intervals. Let’s start with the confidence intervals, which are the frequentist way to express uncertainty about an estimate of a population mean, a population proportion or some other parameter.</p>
<p>A confidence interval has the form of an upper and lower bound.</p>
<p><span class="math display">\[L, U = \text{pe} \pm \text{se} \times \text{cv}\]</span></p>
<ul>
<li>L = lower, U = upper</li>
<li>pe = point estimate, se = standard error, cv = critical value</li>
</ul>
<p>Most importantly, the interpretation of a 95% confidence interval on the mean is that <strong>“95% of similarly constructed intervals will contain the true mean”</strong>, not “the probability that true mean lies between <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span> is 0.95”.</p>
<p>The reason for this frequentist wording is that a frequentist may not express his uncertainty as a probability. The true mean is either within the interval or not, so the probability is zero or one. The problem is that the frequentist does not know which is the case.</p>
<p>On the other hand, Bayesians have no such qualms. It is fine for us to say that <strong>“the probability that the true mean is contained within a given interval is 0.95”</strong>. To distinguish our intervals from confidence intervals, we call them <strong>credible intervals</strong>.</p>
<p>Recall the RU-486 example. When the analyst used the beta-binomial family, she took the prior as <span class="math inline">\(p \sim \text{beta}(1,1)\)</span>, the uniform distribution, where <span class="math inline">\(p\)</span> is the probability of a child having a mother who received RU-486.</p>
<p>After we observed four children born to mothers who received conventional therapy, her posterior is <span class="math inline">\(p|x \sim \text{beta}(1,5)\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x.vector =<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">0</span>, <span class="dt">to=</span><span class="dv">1</span>, <span class="dt">by=</span><span class="fl">0.001</span>)
y.vector =<span class="st"> </span><span class="kw">dbeta</span>(x.vector,<span class="dv">1</span>,<span class="dv">5</span>)

<span class="kw">plot</span>(x.vector, y.vector, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Beta(1,5)&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>)</code></pre></div>
<div class="figure">
<img src="02-inference-03-credible_files/figure-html/unnamed-chunk-1-1.png" alt="RU-486 Posterior" width="672" />
<p class="caption">
(#fig:unnamed-chunk-1)RU-486 Posterior
</p>
</div>
</div>
<div id="predictive-inference" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Predictive Inference</h3>
<!--chapter:end:02-inference-03-credible.Rmd-->
</div>
</div>
</div>
<div id="losses-and-decision-making" class="section level1">
<h1><span class="header-section-number">3</span> Losses and Decision-making</h1>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
</div>
<div id="losses-and-decision-making-1" class="section level2">
<h2><span class="header-section-number">3.2</span> Losses and Decision Making</h2>
</div>
<div id="working-with-loss-functions" class="section level2">
<h2><span class="header-section-number">3.3</span> Working with Loss Functions</h2>
</div>
<div id="minimizing-expectated-loss-for-hypothesis-testing" class="section level2">
<h2><span class="header-section-number">3.4</span> Minimizing Expectated Loss for Hypothesis Testing</h2>
</div>
<div id="posterior-probabilities-of-hypotheses-and-bayes-factors" class="section level2">
<h2><span class="header-section-number">3.5</span> Posterior Probabilities of Hypotheses and Bayes Factors</h2>
<!--chapter:end:03-decision-00-intro.Rmd-->
</div>
</div>
<div id="inference-for-multiple-parameters" class="section level1">
<h1><span class="header-section-number">4</span> Inference for Multiple Parameters</h1>
<p>This chapter is focused on the extending the Normal-Normal conjugate family introduced in @ref(sec:normal-normal) to the problem of inference in a Normal population with an unknown mean and variance. We will introduce the Normal-Gamma conjugate family for inference about the unknown mean and variance and will present Monte Carlo simulation for inference about functions of the parameters as well as sampling from predictive distributions, which can assist with prior elucidation. For situations when limited prior information is available, we discuss a limiting case of the Normal-Gamma conjugate family, leading to priors that can be used for a reference analysis. Finally, we will show how to create a more flexible and robust prior distribution by using mixtures of the Normal-Gamma conjugate prior. For inference in this case we will introduce Markov Chain Monte carlo, a powerful simulation method for Bayesian inference.</p>
<p>It is assumed that the readers have mastered the concepts of one-parameter Normal-Normal conjugate priors. Calculus is not required for this chapter; however, for those who have that backgound and would like to go deeper, we shall present starred sections with more details on the derivations.</p>
<!--chapter:end:04-normal-00-intro.Rmd-->
<div id="sec:normal-gamma" class="section level2">
<h2><span class="header-section-number">4.1</span> Inference for Normal Mean with Unknown Variance</h2>
<p>In @ref(sec:normal-normal) we described the normal-normal conjugate family for inference about an unknown mean <span class="math inline">\(\mu\)</span> with a known standard deviation <span class="math inline">\(\sigma\)</span> when the data were assumed to be a random sample from a normal population. In this section we will introduce the normal-gamma conjugate family for the common situation when <span class="math inline">\(\sigma\)</span> is unknown.</p>
<div id="sampling-model" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Sampling Model</h3>
<p>Recall that a conjugate pair is a sampling model for the data and prior distribution for the unknown parameters such that the posterior distribution is in the same family of distributions as the prior distribution. We will assume that the data are a random sample of size <span class="math inline">\(n\)</span> from a normal population with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>; the following is a mathematical shorthand to represent this distribution assumption</p>
<p><span class="math display">\[\begin{equation}
Y_1, \ldots Y_n  \iid
\textsf{N}(\mu, \sigma^2) 
\end{equation}\]</span> where iid above the distributed as symbol ‘<span class="math inline">\(\sim\)</span>’ indicates that each of the observations are <strong>i</strong>ndependent of the others (given <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>) and are <strong>i</strong>dentically <strong>d</strong>istributed. As both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> unknown, we will need to specify a <strong>joint</strong> prior distribution to describe our prior uncertainty about them.</p>
</div>
<div id="conjugate-prior" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Conjugate prior</h3>
If you recall from @ref(sec:normal-normal) the conjugate prior for <span class="math inline">\(\mu\)</span> with a known standard deviation <span class="math inline">\(\sigma\)</span> was a normal distribution. We will build on this to specify the conditional prior distribution for <span class="math inline">\(\mu\)</span> as
<span class="math display">\[\begin{equation}
\mu \mid \sigma^2   \sim  \textsf{N}(m_0, \sigma^2/n_0)
(\#eq:04-conjugate-normal)
\end{equation}\]</span>
<p>with hyper-parameters <span class="math inline">\(m_0\)</span>, the prior mean for <span class="math inline">\(\mu\)</span>, and <span class="math inline">\(\sigma^2/n_0\)</span> the prior variance. While previously the variance was a known constant <span class="math inline">\(\tau^2\)</span>, replacing <span class="math inline">\(\tau^2\)</span> with a multiple of <span class="math inline">\(\sigma^2\)</span> is necessary for the joint conjugate prior. Because <span class="math inline">\(\sigma\)</span> has the same units as the data, the hyper-parameter <span class="math inline">\(n_0\)</span> is unitless, but is used to express our prior precision about <span class="math inline">\(\mu\)</span> with larger values of <span class="math inline">\(n_0\)</span> indicating more precision and smaller values less precision. We will see later how the hyper-parameter <span class="math inline">\(n_0\)</span> may be interpreted as a prior sample size.</p>
As <span class="math inline">\(\sigma^2\)</span> is unknown, a Bayesian would use a prior distribution to describe the uncertainty about the variance before seeing data. Since the variance is non-negative, continuous, and with no upper limit, you might think that a gamma distribution would be a candidate for a conjugate prior for the variance, based on the distributions that we have seen so far. That is close, but it turns out that it is actually the inverse of the variance, which is known as the precision, that has a conjugate gamma prior distribution. Letting <span class="math inline">\(\phi = 1/\sigma^2\)</span> denote the precision or inverse variance, the conjugate prior for <span class="math inline">\(\phi\)</span>,
<span class="math display">\[\begin{equation}
\phi \sim \textsf{Gamma}\left(\frac{v_0}{2}, \frac{v_0 s^2_0}{2} \right)
(\#eq:04-conjugate-gamma)
\end{equation}\]</span>
is a gamma distribution with prior degrees of freedom <span class="math inline">\(v_0\)</span> and prior variance <span class="math inline">\(s^2_0\)</span>. Equivalently we may say that the inverse of the variance has a <span class="math display">\[1/\sigma^2 \sim \textsf{Gamma}(v_0/2, s^2_0 v_0/2)\]</span> gamma distribution. Together the Normal conditional distribution for <span class="math inline">\(\mu\)</span> given <span class="math inline">\(\sigma^2\)</span> in @ref(eq:04-conjugate-normal) and the marginal Gamma distribution for <span class="math inline">\(\phi\)</span> in @ref(eq:04-conjugate-gamma) leads to a joint distribution for the pair <span class="math inline">\((\mu, \phi)\)</span> that we will call the Normal-Gamma family of distributions
<span class="math display">\[\begin{equation}(\mu, \phi) \sim \textsf{NormalGamma}(m_0, n_0, s^2_0, v_0)
(\#eq:04-cojugate-normal-gamma)
\end{equation}\]</span>
<p>with four hyperparameters <span class="math inline">\(m_0\)</span>, <span class="math inline">\(n_0\)</span>, <span class="math inline">\(s^2_0\)</span>, and <span class="math inline">\(v_0\)</span>.</p>
</div>
<div id="posterior-distribution" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Posterior Distribution</h3>
As a conjugate family the posterior distribution of the parameters is in the same family as the prior distribution. As a conjugate prior for a sample from a normal distribution, the posterior is also Normal-Gamma
<span class="math display">\[\begin{equation}
(\mu, \phi) \mid \text{data} \sim \textsf{NormalGamma}(m_n, n_n, s^2_n, v_n)
\end{equation}\]</span>
where the subscript <span class="math inline">\(n\)</span> on the hyper-parameters indicates the updated values after seeing the <span class="math inline">\(n\)</span> observations from the data:
<span class="math display">\[\begin{eqnarray*}
m_n &amp; = &amp; \frac{n \bar{Y} + n_0 m_0} {n + n_0}  \\
&amp; \\
n_n &amp; = &amp; n_0 + n  \\
v_n &amp; = &amp; v_0 + n  \\
s^2_n &amp; =  &amp; \frac{1}{v_n}\left[s^2_0 v_0 + s^2 (n-1) + \frac{n_0 n}{n_n} (\bar{Y} - m_0)^2 \right] 
\end{eqnarray*}\]</span>
<p>The updated hyperparameter <span class="math inline">\(m_n\)</span> in the posterior distribution of <span class="math inline">\(\mu\)</span> is the posterior mean, which is a weighted average of the sample mean <span class="math inline">\(\bar{Y}\)</span> and prior mean <span class="math inline">\(m_0\)</span> with weights <span class="math inline">\(n/(n + n_0\)</span> and <span class="math inline">\(n_0/(n + n_0)\)</span> respectively. The posterior sample size <span class="math inline">\(n_n\)</span> is the sum of the prior sample size <span class="math inline">\(n_n\)</span> and the sample size <span class="math inline">\(n\)</span>, representing the combined precision of the estimate for <span class="math inline">\(\mu\)</span>.</p>
<p>The posterior degrees of freedom <span class="math inline">\(v_n\)</span> are also increased by adding the sample size <span class="math inline">\(n\)</span> to the prior degrees of freedom <span class="math inline">\(v_0\)</span>.</p>
<p>The posterior variance hyper-parameter <span class="math inline">\(s^2_n\)</span> combines three sources of information about <span class="math inline">\(\sigma\)</span> in terms of sums of squared deviations. The first term in the square brackets is the sample variance times the sample degrees of freedom which is the sample sum of squares. The second term represents the prior sum of squares, while the third term is based on the squared difference of the sample mean and prior mean. We then divide by the posterior degrees of freedom to get the new variance.</p>
<p>The joint Normal-Gamma distribution for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span>, <span class="math inline">\((\mu, \phi) \mid \data \sim \textsf{NormalGamma}(m_n, n_n, s^2_n, v_n)\)</span> is equivalent to a hierarchical model with <span class="math inline">\(\mu\)</span> given <span class="math inline">\(\sigma\)</span> having a conditional normal distribution <span class="math display">\[\begin{aligned}
\mu \mid \data, \sigma^2  &amp;\sim  {\textsf{N}}(m_n, \sigma^2/n_n)  \\
1/\sigma^2 \mid \data  &amp; \sim   {\textsf{Gamma}}(v_n/2, s^2_n v_n/2) \pause
\end{aligned}
\]</span> and the inverse variance having a marginal gamma distribution.</p>
</div>
<div id="marginal-distribution-for-mu" class="section level3">
<h3><span class="header-section-number">4.1.4</span> Marginal Distribution for <span class="math inline">\(\mu\)</span></h3>
<p>Since we are interested in inference about mu unconditionally, we need the marginal distribution of mu that averages over the uncertainty in <span class="math inline">\(\sigma\)</span>. One can show by integration that the marginal distribution for <span class="math inline">\(\mu\)</span> is a Student t distribution <span class="math display">\[\begin{aligned} \mu \mid \data \sim {\textsf{t}}(v_n, m_n, s^2_n/n_n) \pause
 \Leftrightarrow  t = \frac{\mu - m_n}{s_n/\sqrt{n_n}} \sim {\textsf{t}}(v_n, 0 , 1)
 \end{aligned}
\]</span> with density <span class="math display">\[
\begin{aligned}
p(t) =\frac{\Gamma\left(\frac{v_n + 1}{2} \right)}
{\sqrt{\pi v_n} \Gamma\left(\frac{v_n}{2} \right)}
\left(1 + \frac{1}{v_n}\frac{(\mu - m_n)^2} {s^2_n/n_n} \right)^{-\frac{v_n+1}{2}}
\end{aligned}\]</span> with the degrees of freedom <span class="math inline">\(v_n\)</span>, a location parameter <span class="math inline">\(m_n\)</span> and squared scale parameter that is the posterior variance parameter divided by the posterior sample size.</p>
<p>standardizing mu by subtracting the location and dividing by the scale yields a standard t distribution with degrees of freedom v_n, location 0 and scale 1. The latter representation allows us to use standard statistical functions for posterior inference.</p>
<p>Let’s look at an example based on a sample of total trihalomethanes or TTHM in tapwater from a city in NC, that can be loaded from the <code>statsr</code> package</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(statsr)
<span class="kw">data</span>(tapwater)</code></pre></div>
<p>Using prior information about TTHM from the city, I will use a Normal-Gamma prior distribution with prior mean of 35 parts per billion based on a prior sample size of twenty-five and an estimate of the variance of one hundred fifty-six point two five with degrees of freedom twenty-four. In section <strong>ADD REFERENCE</strong>, we will describe how we arrived at these values.</p>
<p>Using the sample mean of 55.5 and the sample variance five hundred forty point seven from the sample of size 28 we obtain the following update the hyper-parameters</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_0 =<span class="st"> </span><span class="dv">35</span>; n_0 =<span class="st"> </span><span class="dv">25</span>; s2_0 =<span class="st"> </span><span class="fl">156.25</span>; v_0 =<span class="st"> </span>n_0 -<span class="st"> </span><span class="dv">1</span>

Y =<span class="st"> </span>tapwater$tthm
ybar =<span class="st"> </span><span class="kw">mean</span>(Y)
s2 =<span class="st"> </span><span class="kw">var</span>(Y)
n =<span class="st"> </span><span class="kw">length</span>(Y)
n_n =<span class="st"> </span>n_0 +<span class="st"> </span>n
m_n =<span class="st"> </span>(n*ybar +<span class="st"> </span>n_0*m_0)/n_n
v_n =<span class="st"> </span>v_0 +<span class="st"> </span>n
s2_n =<span class="st"> </span>((n<span class="dv">-1</span>)*s2 +<span class="st"> </span>v_0*s2_0 +<span class="st"> </span>n_0*n*(m_0 -<span class="st"> </span>ybar)^<span class="dv">2</span>/n_n)/v_n</code></pre></div>
<p>Prior <span class="math inline">\(\textsf{NormalGamma}(35, 25, \Sexpr{s2_0}, \Sexpr{v_0})\)</span></p>
<p>Data <span class="math inline">\(\bar{Y} = \Sexpr{ybar}\)</span>, <span class="math inline">\(s^2 = \Sexpr{s2}\)</span>, <span class="math inline">\(n = \Sexpr{n}\)</span> providing the normal-gamma posterior that summarizes our posterior uncertainty after seeing the data.</p>
<p>To find a credible interval for the mean, we use the Student t distribution. Since the distribution of mu is unimodal and symmetric, the shortest 95 percent credible interval or the Highest Posterior Density interval, HPD for short, is the orange interval given by the Lower endpoint L and upper endpoint U where the probability that mu is in the interval (L, U) is the shaded area which is equal to zero point nine five.</p>
<p>using the standardized t distribution and some algebra, these values are based on the quantiles of the standard t distribution times the scale plus the posterior mean and should look familiar to expressions for confidence intervals from frequentist statistics.</p>
<p>The following code illustrates using R to calculate the 95 percent credible interval using quantiles from the standard t distribution. The tap water data are available from the statsr package.</p>
<p>Based on the updated posterior, we find that there is a 95 chance that the mean TTHM concentration is between 39.9 parts per billion and 51.8 parts per billion.</p>
<p>To recap, we introduced the normal -gamma conjugate prior for inference about an unknown mean and variance for samples from a normal distribution.</p>
<p>We described how the joint normal-gamma distribution leads to the student t distribution for inference about mu when sigma is unknown,</p>
<p>and showed how to obtain credible intervals for mu using R.</p>
<p>next, we will introduce Monte Carlo sampling to explore prior and posterior distributions in more detail.</p>
<!--chapter:end:04-normal-01-conjugate.Rmd-->
</div>
</div>
<div id="monte-carlo-simulation" class="section level2">
<h2><span class="header-section-number">4.2</span> Monte Carlo Simulation</h2>
<!--chapter:end:04-normal-02-Monte-Carlo.Rmd-->
</div>
<div id="predictive-distributions" class="section level2">
<h2><span class="header-section-number">4.3</span> Predictive Distributions</h2>
<!--chapter:end:04-normal-03-predictive.Rmd-->
</div>
<div id="reference-priors" class="section level2">
<h2><span class="header-section-number">4.4</span> Reference Priors</h2>
<!--chapter:end:04-normal-04-reference.Rmd-->
</div>
<div id="beyond-conjugate-priors-using-mixtures" class="section level2">
<h2><span class="header-section-number">4.5</span> Beyond Conjugate Priors using Mixtures</h2>
<!--chapter:end:04-normal-05-mixtures.Rmd-->
</div>
<div id="markov-chain-monte-carlo" class="section level2">
<h2><span class="header-section-number">4.6</span> Markov Chain Monte Carlo</h2>
<!--chapter:end:04-normal-06-MCMC.Rmd-->
</div>
<div id="excercises" class="section level2">
<h2><span class="header-section-number">4.7</span> Excercises</h2>
<!--chapter:end:04-normal-07-exercises.Rmd-->
</div>
</div>
<div id="hypothesis-testing-for-one-and-two-normal-samples" class="section level1">
<h1><span class="header-section-number">5</span> Hypothesis Testing for One and Two Normal Samples</h1>
<div id="bayes-factors-for-testing-a-normal-mean-variance-known" class="section level2">
<h2><span class="header-section-number">5.1</span> Bayes Factors for Testing a Normal Mean: Variance Known</h2>
</div>
<div id="bayes-factors-for-testing-a-normal-mean-variance-unknown" class="section level2">
<h2><span class="header-section-number">5.2</span> Bayes Factors for Testing a Normal Mean: Variance Unknown</h2>
</div>
<div id="bayes-factors-for-hypotheses-about-means-in-two-groups" class="section level2">
<h2><span class="header-section-number">5.3</span> Bayes Factors for Hypotheses about Means in Two Groups</h2>
</div>
<div id="credible-intervals-after-hypothesis-testing" class="section level2">
<h2><span class="header-section-number">5.4</span> Credible Intervals after Hypothesis Testing</h2>
</div>
<div id="exercises-1" class="section level2">
<h2><span class="header-section-number">5.5</span> Exercises</h2>
<!--chapter:end:05-testing-00.Rmd-->
</div>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
